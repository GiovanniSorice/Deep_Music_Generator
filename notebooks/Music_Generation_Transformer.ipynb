{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generation_Transformer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOcHA+Z6ZOq1W8g/O1H+ujt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Deep_Music_Generator/blob/main/notebooks/Music_Generation_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ3GwlYmvNT"
      },
      "source": [
        "# Transformer Music Generator "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNwQUwLIm7oW"
      },
      "source": [
        "\n",
        "\n",
        "In this notebook, we use an Transformer to generate some music.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFVGA5D4azA4"
      },
      "source": [
        "**This notebook was inspired (and part of the code comes from it) by [Music_Generation_LSTM](https://colab.research.google.com/drive/19TQqekOlnOSW36VCL8CPVEQKBBukmaEQ#scrollTo=DDOBVWULXfpz)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsb9kaJmWHN",
        "outputId": "44ba5c04-97c3-4d85-f72a-f6e374acb568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install compressive_transformer_pytorch"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting compressive_transformer_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/30/39/b8caf2671abcb8615977c08766aa9f450addd6949f57c7dda87224e844b5/compressive_transformer_pytorch-0.3.20-py3-none-any.whl\n",
            "Collecting mogrifier\n",
            "  Downloading https://files.pythonhosted.org/packages/77/01/62a55d0f8048e788fce435f2ade6478f443e4e53ed9b89b55ba0fc42c198/mogrifier-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from compressive_transformer_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (1.18.5)\n",
            "Installing collected packages: mogrifier, compressive-transformer-pytorch\n",
            "Successfully installed compressive-transformer-pytorch-0.3.20 mogrifier-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mi6KoBmX44A"
      },
      "source": [
        "import torch\n",
        "from compressive_transformer_pytorch import CompressiveTransformer\n",
        "from compressive_transformer_pytorch import AutoregressiveWrapper\n",
        "from torchsummary import summary\n",
        "import tqdm\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmj0efInB_L"
      },
      "source": [
        "\n",
        "\n",
        "**Load dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USZpREpD6VTY"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import utils\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import pickle\n",
        "from music21 import converter, instrument, stream, note, chord"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwF2wx4oRZXW"
      },
      "source": [
        "# Set to false if you are not running\n",
        "# this notebook in Google Colaboratory\n",
        "run_on_colab = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2w9a2MknGmP"
      },
      "source": [
        "**Set hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnnLeO8Emsx3"
      },
      "source": [
        "# output directory name:\n",
        "output_dir = 'model_output/LSTM'\n",
        "\n",
        "# training:\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "# vector-space embedding: \n",
        "n_dim = 64 \n",
        "sequence_length = 16\n",
        "\n",
        "# LSTM layer architecture:\n",
        "n1_lstm = 256 \n",
        "drop1_lstm = 0.2\n",
        "n2_lstm = 256 \n",
        "drop2_lstm = 0.2\n",
        "n3_lstm = 256 \n",
        "drop3_lstm = 0.2\n",
        "\n",
        "# dense layer architecture: \n",
        "n_dense = 128\n",
        "drop_dense = 0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvBjPl0cbI0_"
      },
      "source": [
        "**Google drive configuration (only Colab)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKil2p6sM2gZ",
        "outputId": "8def953a-05bc-4ecf-bd72-2dbd656c9042",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if(run_on_colab):\n",
        "  from google.colab import drive\n",
        "  # This will prompt for authorization.\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU3gQinYmutQ"
      },
      "source": [
        "**Load data** \\\\\n",
        "Original MIDI files\n",
        " I have obtained  **MIDI files** from [The Lakh MIDI Dataset v0.1](https://colinraffel.com/projects/lmd/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wavgJZNpcR_f"
      },
      "source": [
        "## Processing data\n",
        "\n",
        "Let's process the files, and load them into **music21**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vILKBwYIcOvX",
        "outputId": "2f19985f-8adc-49bc-8687-c99c75471f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file = \"/content/drive/My Drive/ISPR_project/midi_songs/Andra tutto bene ('58).1.mid\"\n",
        "midi = converter.parse(file)\n",
        "notes_to_parse = midi.flat.notes\n",
        "for element in notes_to_parse[:10]:\n",
        "  print(element, element.offset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<music21.chord.Chord F3 F2> 4.0\n",
            "<music21.note.Note A> 4.0\n",
            "<music21.chord.Chord B1 F#3 F#2> 4.0\n",
            "<music21.note.Note F> 4.0\n",
            "<music21.chord.Chord C4 F4> 4.0\n",
            "<music21.chord.Chord F#3 C#6 F#2> 4.5\n",
            "<music21.note.Note C#> 4.75\n",
            "<music21.chord.Chord F#2 E2 F#3> 5.0\n",
            "<music21.chord.Chord A4 A3 F4 C4 A3> 5.0\n",
            "<music21.note.Note F> 5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjyrXfKic2kI"
      },
      "source": [
        "I will process all MIDI files obtaining data from each note of chord.\n",
        "\n",
        "- If I process a **note**, I will store in the list a string representing the pitch (the note name) and the octave.\n",
        "\n",
        "- If I process a **chord** (Remember that chords are set of notes that are played at the same time) I will store a different type of string with numbers separated by dots. Each number represents the pitch of a chord note. \n",
        "\n",
        "As you can see, **I are not considering yet time offsets of each element**. In this first version, we won't consider them, so all the notes and chords will have the same duration. Maybe, in the future, I will consider them.\n",
        "\n",
        "I are creating a big list with all the elements of all the compositions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawbQHYVTOFM",
        "outputId": "7de1cb2e-d689-4dfa-a39f-6866fe03eb59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "notes = []\n",
        "for i,file in enumerate(glob.glob(\"/content/drive/My Drive/ISPR_project/midi_songs/*.mid\")):\n",
        "  midi = converter.parse(file)\n",
        "  print('\\r', 'Parsing file ', i, \" \",file, end='')\n",
        "  notes_to_parse = None\n",
        "  try: # file has instrument parts\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "    notes_to_parse = s2.parts[0].recurse() \n",
        "  except: # file has notes in a flat structure\n",
        "    notes_to_parse = midi.flat.notes\n",
        "  for element in notes_to_parse:\n",
        "    if isinstance(element, note.Note):\n",
        "      notes.append(str(element.pitch))\n",
        "    elif isinstance(element, chord.Chord):\n",
        "      notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "with open('notes', 'wb') as filepath:\n",
        "  pickle.dump(notes, filepath)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Parsing file  3   /content/drive/My Drive/ISPR_project/midi_songs/Andra tutto bene ('58).1.mid"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuHePM_3dMXM"
      },
      "source": [
        "I obtain the number of different notes in our dataset, because this will be the **number of possible output classes**  of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEiySfEnTzyz",
        "outputId": "0b9a65cc-e6d2-4d55-f59e-4e89a41b1cb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Count different possible outputs\n",
        "n_vocab = (len(set(notes)))\n",
        "n_vocab"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-mABhgUnTcV"
      },
      "source": [
        "**Preprocess data** \\\\\n",
        "Now, there is some **data processing** that I have to do:\n",
        "\n",
        "- I will map each pitch or chord to an integer\n",
        "- I will create pairs of input sequences and its corresponding output note\n",
        "\n",
        "I can try different **sequence_length** to obtain different results. In this first version, I will use a sequence_length of 100.\n",
        "\n",
        "The network will made its prediction of the next note (or chord), based on the previous *sequence_length* notes (or chords). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHg-J6J4ouPB"
      },
      "source": [
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len, segments):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "        self.segments = segments\n",
        "        self.total_len = seq_len * segments\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.total_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.total_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.total_len"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4PpfIFRnWIA"
      },
      "source": [
        "# get all pitch names\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "# create a dictionary to map pitches to integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "network_input = []\n",
        "network_output = []\n",
        "# create input sequences and the corresponding outputs\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "  # Map pitches of sequence_in to integers\n",
        "  network_input.append([note_to_int[char] for char in notes[i:i + sequence_length]])\n",
        "n_patterns = len(network_input)\n",
        "# reshape the input into a format compatible with LSTM layers\n",
        "network_input = np.reshape(network_input, (n_patterns,1, sequence_length))\n",
        "# normalize input\n",
        "#network_input = network_input / float(n_vocab)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRPauXUdq5Y"
      },
      "source": [
        "Let's see the new metwork_input size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8eQQMbxhUkN",
        "outputId": "5750c375-0c8d-44c6-b145-8eb53a9a2928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network_input.shape"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4987, 1, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6--Wc8UXnVgY"
      },
      "source": [
        "**Design neural network architecture** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ztPAQsnb7T"
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = CompressiveTransformer(\n",
        "    num_tokens = n_vocab,\n",
        "    dim = sequence_length,\n",
        "    depth = 6,\n",
        "    seq_len = 1024,\n",
        "    mem_len = 1024,\n",
        "    cmem_len = 256,\n",
        "    cmem_ratio = 4,\n",
        "    memory_layers = [5,6]\n",
        "    )\n",
        "\n",
        "    model = AutoregressiveWrapper(model)\n",
        "    model.cuda()\n",
        "    return model"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nsNVMocnhNC",
        "outputId": "60faa0bd-5886-42ea-e282-f21620f96a8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_network(network_input,n_vocab)\n",
        "\n",
        "print(model)\n",
        "#for loss, aux_loss, _ in model(inputs, return_loss = True):\n",
        "#    (loss + aux_loss).backward()\n"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AutoregressiveWrapper(\n",
            "  (net): CompressiveTransformer(\n",
            "    (token_emb): Embedding(71, 16)\n",
            "    (to_model_dim): Identity()\n",
            "    (to_logits): Sequential(\n",
            "      (0): Identity()\n",
            "      (1): Linear(in_features=16, out_features=71, bias=True)\n",
            "    )\n",
            "    (attn_layers): ModuleList(\n",
            "      (0): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (1): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (2): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (3): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (4): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (5): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "    )\n",
            "    (ff_layers): ModuleList(\n",
            "      (0): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (1): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (2): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (3): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (4): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (5): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRKI1q5WjwcL"
      },
      "source": [
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "\n",
        "data_train = torch.from_numpy(network_input).cuda()\n",
        "train_dataset = TextSamplerDataset(data_train, sequence_length, n_patterns)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = 32))"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60il158kxfq"
      },
      "source": [
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKzGZfW54tuF",
        "outputId": "32308b0b-b073-4751-fdfe-3a1dce84c11b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(data_train[0])\n"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[49, 56, 67, 28,  4, 12, 59, 12, 59, 12,  4, 12, 11, 12, 59, 12]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHBV4oty6RN7",
        "outputId": "d104a9dd-b7b5-461d-faab-425f6e2d1b86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "n_patterns"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4987"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqX3PsrJkyNN",
        "outputId": "b75c4fd3-8a1d-403d-d3f8-da132b4e5315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# training\n",
        "for i in tqdm.tqdm(range(n_batches), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    grad_accum_every = 1\n",
        "\n",
        "    for k in range(31):\n",
        "      for mlm_loss, aux_loss, is_last in model(data_train[k], max_batch_size = 16, return_loss = True):\n",
        "          loss = mlm_loss + aux_loss\n",
        "          (loss / grad_accum_every).backward()\n",
        "\n",
        "          print(f'training loss: {mlm_loss.item():.4f} | aux_loss: {aux_loss.item():.4f}')\n",
        "\n",
        "          if k == 30:\n",
        "              print(k)\n",
        "              torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "              optim.step()\n",
        "              optim.zero_grad()\n",
        "\n"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "training:   0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n",
            "training loss: 4.2864 | aux_loss: 0.0000\n",
            "training loss: 4.2816 | aux_loss: 0.0000\n",
            "training loss: 4.2844 | aux_loss: 0.0000\n",
            "training loss: 4.2794 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2825 | aux_loss: 0.0000\n",
            "training loss: 4.2843 | aux_loss: 0.0000\n",
            "training loss: 4.2793 | aux_loss: 0.0000\n",
            "training loss: 4.2811 | aux_loss: 0.0000\n",
            "training loss: 4.2791 | aux_loss: 0.0000\n",
            "training loss: 4.2810 | aux_loss: 0.0000\n",
            "training loss: 4.2792 | aux_loss: 0.0000\n",
            "training loss: 4.2946 | aux_loss: 0.0000\n",
            "training loss: 4.2891 | aux_loss: 0.0000\n",
            "training loss: 4.2932 | aux_loss: 0.0000\n",
            "training loss: 4.2922 | aux_loss: 0.0000\n",
            "training loss: 4.2943 | aux_loss: 0.0000\n",
            "training loss: 4.2921 | aux_loss: 0.0000\n",
            "training loss: 4.2944 | aux_loss: 0.0000\n",
            "training loss: 4.2871 | aux_loss: 0.0000\n",
            "training loss: 4.2911 | aux_loss: 0.0000\n",
            "training loss: 4.2870 | aux_loss: 0.0000\n",
            "30\n",
            "training loss: 4.2881 | aux_loss: 0.0000\n",
            "training loss: 4.2807 | aux_loss: 0.0000\n",
            "training loss: 4.2906 | aux_loss: 0.0000\n",
            "training loss: 4.2895 | aux_loss: 0.0000\n",
            "training loss: 4.2849 | aux_loss: 0.0000\n",
            "training loss: 4.2875 | aux_loss: 0.0000\n",
            "training loss: 4.2856 | aux_loss: 0.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-258-aa1611fdc2d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mmlm_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlm_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maux_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mgrad_accum_every\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/compressive_transformer_pytorch/autoregressive_wrapper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, max_batch_size, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0mis_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad_accumulate_every\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi_seg_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_seg_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                 \u001b[0mnew_mems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memories, mask)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mmemories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmem_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmem_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmem_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_aux_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConvCompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/compressive_transformer_pytorch/compressive_transformer_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, memories, pos_emb, input_mask, calc_memory, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bhij,bhjd->bhid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1678\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1679\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbO-XA3Dfrd2"
      },
      "source": [
        "In case we want to use previously trained weights, to continue the training in the point we left it, we should load them into the model.\n",
        "\n",
        "This is very useful in Google Colaboratory, that usually kills the virtual machine that is executing the Jupyter notework after a certime amount of time. If this happens to you, you should have to look for the last weights file in your configured Drive account and use it to train the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFbSthkLUwmx"
      },
      "source": [
        "# In case we want to use previously trained weights\n",
        "weights = \"\"\n",
        "if(len(weights)>0): model.load_weights(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqyWj37PnfaS"
      },
      "source": [
        "**Configure model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiAxaVxlnpS5"
      },
      "source": [
        "filepath = \"/content/drive/My Drive/ISPR_project/LSTM{epoch:02d}-{loss:.4f}.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=0,\n",
        "                             save_best_only=True,mode='min')\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp2KgUt6nvNj"
      },
      "source": [
        "**Train!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu49Lazy4PgR",
        "outputId": "f756d92c-6b57-457f-aa7f-5bb828d959f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "prova=2500\n",
        "prediction = model.predict(network_input[prova], verbose=0)\n",
        "index = np.argmax(prediction)\n",
        "index2 = np.argmax(network_output[prova])\n",
        "print(index)\n",
        "print(index2)\n",
        "\n",
        "result = int_to_note[index]\n",
        "print('\\r', 'Predicted ', i, \" \",result, end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n",
            "52\n",
            "\r Predicted  4992   F#3"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNheAnB7nzZg",
        "outputId": "2d205cdb-6c24-4c48-99a5-99798cffe56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        }
      },
      "source": [
        "model.fit(network_input, network_output, epochs=epochs, batch_size=8, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 4.1225\n",
            "Epoch 2/100\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 3.7071\n",
            "Epoch 3/100\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 3.6514\n",
            "Epoch 4/100\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 3.6245\n",
            "Epoch 5/100\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 3.6052\n",
            "Epoch 6/100\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 3.5961\n",
            "Epoch 7/100\n",
            "148/625 [======>.......................] - ETA: 3s - loss: 3.5663"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-408-b18a839f11bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAgrzFyRn3uq"
      },
      "source": [
        "**Music generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1CA_EQdoN5P",
        "outputId": "c545d547-9186-4805-e30f-67425a246ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "# In case we want to use other previously trained weights\n",
        "weights = \"path/to/weights\"\n",
        "if(len(weights)>0): model.load_weights(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-44fe414b8109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# In case we want to use other previously trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"path/to/weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m         \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     93\u001b[0m   \"\"\"\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on path/to/weights: Not found: path/to; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WtYEXpyoPPK"
      },
      "source": [
        "# Generate network input again\n",
        "network_input = []\n",
        "output = []\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "  sequence_in = notes[i:i + sequence_length]\n",
        "  sequence_out = notes[i + sequence_length]\n",
        "  network_input.append([note_to_int[char] for char in sequence_in])\n",
        "  output.append(note_to_int[sequence_out])\n",
        "n_patterns = len(network_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuUGi5rVgbJQ"
      },
      "source": [
        "The workflow now is:\n",
        "\n",
        "\n",
        "1.   Pick a **seed sequence** randomly from your list of inputs (*pattern* variable)\n",
        "2.   Pass it as input for your model to generate a new element (note or chord)\n",
        "3.   Add the new element to your final song and to your *pattern* list\n",
        "4.   Remove the first item from *pattern*\n",
        "5.   Go to step 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUTEiS0NXtkl",
        "outputId": "28f31c70-9954-4033-d374-fc421cebe50c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "# pick a random sequence from the input as a starting point for the prediction\n",
        "start = np.random.randint(0, len(network_input)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "pattern = network_input[start]\n",
        "prediction_output = []\n",
        "# generate 500 notes\n",
        "for i,note_index in enumerate(range(10)):\n",
        "  prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "  prediction_input = prediction_input / float(n_vocab)\n",
        "  prediction = model.predict(prediction_input, verbose=0)\n",
        "  index = np.argmax(prediction)\n",
        "  result = int_to_note[index]\n",
        "  print('\\r', 'Predicted ', i, \" \",result, end='')\n",
        "  prediction_output.append(result)\n",
        "  pattern.append(index)\n",
        "  pattern = pattern[1:len(pattern)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Predicted  9   G4"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lp5WcPlghe5"
      },
      "source": [
        "The last step is creating a MIDI file from the predictions.\n",
        "\n",
        "**music21** will help us again for this task. We should create a **Stream** and add to it the predicted notes and chords.\n",
        "\n",
        "We are adding an offset of 0.5 between elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7xYCPULXwV-",
        "outputId": "c341ff0c-a808-47dd-f5e1-6e9967d2b3c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in prediction_output:\n",
        "    # pattern is a chord\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_output.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    }
  ]
}