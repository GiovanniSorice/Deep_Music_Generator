{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generation_Transformer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Deep_Music_Generator/blob/main/notebooks/Music_Generation_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ3GwlYmvNT"
      },
      "source": [
        "# Transformer Music Generator "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNwQUwLIm7oW"
      },
      "source": [
        "\n",
        "\n",
        "In this notebook, we use an Transformer to generate some music.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFVGA5D4azA4"
      },
      "source": [
        "**This notebook was inspired (and part of the code comes from it) by [Music_Generation_LSTM](https://colab.research.google.com/drive/19TQqekOlnOSW36VCL8CPVEQKBBukmaEQ#scrollTo=DDOBVWULXfpz)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmj0efInB_L"
      },
      "source": [
        "\n",
        "\n",
        "**Load dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_tzJeReygOv"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsb9kaJmWHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5543b78a-d8d4-494d-d8c9-ff5aa9a9b277"
      },
      "source": [
        "pip install compressive_transformer_pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting compressive_transformer_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/30/39/b8caf2671abcb8615977c08766aa9f450addd6949f57c7dda87224e844b5/compressive_transformer_pytorch-0.3.20-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from compressive_transformer_pytorch) (1.7.0+cu101)\n",
            "Collecting mogrifier\n",
            "  Downloading https://files.pythonhosted.org/packages/77/01/62a55d0f8048e788fce435f2ade6478f443e4e53ed9b89b55ba0fc42c198/mogrifier-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (1.19.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (0.16.0)\n",
            "Installing collected packages: mogrifier, compressive-transformer-pytorch\n",
            "Successfully installed compressive-transformer-pytorch-0.3.20 mogrifier-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mi6KoBmX44A"
      },
      "source": [
        "import torch\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from compressive_transformer_pytorch import CompressiveTransformer\n",
        "from compressive_transformer_pytorch import AutoregressiveWrapper\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import pickle\n",
        "from music21 import converter, instrument, stream, note, chord\n",
        "import math\n",
        "import shutil\n",
        "from collections import defaultdict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwF2wx4oRZXW"
      },
      "source": [
        "# Set to false if you are not running\n",
        "# this notebook in Google Colaboratory\n",
        "run_on_colab = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2w9a2MknGmP"
      },
      "source": [
        "**Set hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnnLeO8Emsx3"
      },
      "source": [
        "# output directory name:\n",
        "output_dir = '/content/drive/My Drive/ISPR_project/Transformer/pop_rock_model/'\n",
        "current_path ='/content/drive/My Drive/ISPR_project/'\n",
        "# training:\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate=1e-3\n",
        "# vector-space embedding: \n",
        "n_dim = 64 \n",
        "sequence_length = 64\n",
        "\n",
        "\n",
        "VALIDATE_EVERY  = 5\n",
        "\n",
        "GENERATE_EVERY  = 500\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUFOx5yB39xx"
      },
      "source": [
        "**Save model function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQHDRGj838-0"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, output_dir+filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(output_dir+filename, output_dir+'model_best.pth.tar')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvBjPl0cbI0_"
      },
      "source": [
        "**Google drive configuration (only Colab)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYmd3FoQq-Ri",
        "outputId": "5462504c-2928-4ec5-d7af-10b9d5720024"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Dec 19 09:21:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKil2p6sM2gZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c7d5d9-b50c-45c6-c886-ce205b856074"
      },
      "source": [
        "if(run_on_colab):\n",
        "  from google.colab import drive\n",
        "  # This will prompt for authorization.\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU3gQinYmutQ"
      },
      "source": [
        "**Load data** \\\\\n",
        "Original MIDI files\n",
        " I have obtained  **MIDI files** from [The Lakh MIDI Dataset v0.1](https://colinraffel.com/projects/lmd/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wavgJZNpcR_f"
      },
      "source": [
        "## Processing data\n",
        "\n",
        "Let's process the files, and load them into **music21**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vILKBwYIcOvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99bbf5d3-068a-4164-eebf-dcb6e9d8efa6"
      },
      "source": [
        "file = current_path+\"midi_songs/dataset/Metal/Metallica/Am I Evil?.mid\"\n",
        "midi = converter.parse(file)\n",
        "notes_to_parse = midi.flat.notes\n",
        "for element in notes_to_parse[:10]:\n",
        "  print(element, element.offset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<music21.chord.Chord E2 E3 B3 E4> 0.0\n",
            "<music21.chord.Chord E2 E3 B3 E4> 0.0\n",
            "<music21.note.Note E> 0.0\n",
            "<music21.chord.Chord C2 C#3> 0.0\n",
            "<music21.note.Note G#> 2.0\n",
            "<music21.chord.Chord D3 A3 D4> 3.0\n",
            "<music21.chord.Chord D3 A3 D4> 3.0\n",
            "<music21.note.Note D> 3.0\n",
            "<music21.chord.Chord C#3 C2> 3.0\n",
            "<music21.chord.Chord B3 E3 E4> 3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjyrXfKic2kI"
      },
      "source": [
        "I will process all MIDI files obtaining data from each note of chord.\n",
        "\n",
        "- If I process a **note**, I will store in the list a string representing the pitch (the note name) and the octave.\n",
        "\n",
        "- If I process a **chord** (Remember that chords are set of notes that are played at the same time) I will store a different type of string with numbers separated by dots. Each number represents the pitch of a chord note. \n",
        "\n",
        "As you can see, **I are not considering yet time offsets of each element**. In this first version, we won't consider them, so all the notes and chords will have the same duration. Maybe, in the future, I will consider them.\n",
        "\n",
        "I are creating a big list with all the elements of all the compositions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawbQHYVTOFM",
        "outputId": "a2682257-a23c-4762-80e8-4e1d984761fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "source": [
        "notes_for_instruments = []\n",
        "for i,file in enumerate(glob.glob(current_path+\"midi_songs/dataset/*/*/*.mid\")):\n",
        "      midi = converter.parse(file)\n",
        "      print('Parsing file ', i, \" \", file)\n",
        "      notes_to_parse = None\n",
        "      try:  # file has instrument parts\n",
        "          s2 = instrument.partitionByInstrument(midi)\n",
        "          notes_to_parse = s2.recurse()\n",
        "      except:  # file has notes in a flat structure\n",
        "          notes_to_parse = midi.flat.notes\n",
        "      notes_instrument = []\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes_instrument.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes_instrument.append('.'.join(str(n) for n in element.normalOrder))\n",
        "      notes_for_instruments.append(notes_instrument)\n",
        "with open(current_path + 'notes_for_instruments', 'wb') as filepath:\n",
        "    pickle.dump(notes_for_instruments, filepath)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing file  0   /content/drive/My Drive/ISPR_project/midi_songs/dataset/Rock/Queen/All God's People.mid\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-d722bc28a8bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnotes_for_instruments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"midi_songs/dataset/*/*/*.mid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Parsing file '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mnotes_to_parse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(value, *args, **keywords)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueStr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m         return parseFile(valueStr, number=number, format=m21Format,\n\u001b[0;32m-> 1127\u001b[0;31m                          forceSource=forceSource, **keywords)\n\u001b[0m\u001b[1;32m   1128\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalueStr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m         return parseFile(common.cleanpath(valueStr), number=number, format=m21Format,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturnPathlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceSource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(self, fp, number, format, forceSource, storePickle, **keywords)\u001b[0m\n\u001b[1;32m    550\u001b[0m                 \u001b[0menvironLocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintDebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Replacing self.stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0;31m# get a new stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thawedStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthaw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpPickle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zlib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileNumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/converter/__init__.py\u001b[0m in \u001b[0;36mthaw\u001b[0;34m(fp, zipType)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mmusic21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfreezeThaw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreezeThaw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamThawer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzipType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/freezeThaw.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fp, zipType)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mFreezeThawException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bad StreamFreezer format: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpackStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopenStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickleFormat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/freezeThaw.py\u001b[0m in \u001b[0;36munpackStream\u001b[0;34m(self, storage)\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0mstreamObj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stream'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardownSerializationScaffold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstreamObj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/freezeThaw.py\u001b[0m in \u001b[0;36mteardownSerializationScaffold\u001b[0;34m(self, streamObj)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mstreamObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoSort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestoreElementsFromTuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestoreStreamStatusClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/freezeThaw.py\u001b[0m in \u001b[0;36mrestoreElementsFromTuples\u001b[0;34m(self, streamObj)\u001b[0m\n\u001b[1;32m    883\u001b[0m                 \u001b[0;31m# if the spanner stores a part or something in the Stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m                 \u001b[0;31m# for instance in a StaffGroup object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestoreElementsFromTuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubElement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrestoreStreamStatusClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreamObj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/freezeThaw.py\u001b[0m in \u001b[0;36mrestoreElementsFromTuples\u001b[0;34m(self, streamObj)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mstreamObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoreElementsChanged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubElement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstreamObj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msubElement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misStream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m                 \u001b[0;31m# note that the elements may have already been restored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/stream/__init__.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0madds\u001b[0m \u001b[0mnecessary\u001b[0m \u001b[0mStream\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mspecific\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         '''\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/stream/iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, srcStream, filterList, restoreActiveSites, activeInformation, ignoreSorting)\u001b[0m\n\u001b[1;32m     84\u001b[0m                  ignoreSorting=False):\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignoreSorting\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msrcStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misSorted\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msrcStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoSort\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0msrcStream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrcStream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrcStream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/stream/__init__.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m   6442\u001b[0m         \u001b[0;31m# experimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misSorted\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6445\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/stream/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   6442\u001b[0m         \u001b[0;31m# experimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6443\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misSorted\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6444\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6445\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_endElements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msortTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/base.py\u001b[0m in \u001b[0;36msortTuple\u001b[0;34m(self, useSite, raiseExceptionOnMiss)\u001b[0m\n\u001b[1;32m   2379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m         return SortTuple(atEnd, offset, self.priority,\n\u001b[0;32m-> 2381\u001b[0;31m                           self.classSortOrder, isNotGrace, insertIndex)\n\u001b[0m\u001b[1;32m   2382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m     \u001b[0;31m#------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/music21/sorting.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *tupEls, **kw)\u001b[0m\n\u001b[1;32m     95\u001b[0m     '''\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtupEls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSortTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtupEls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj7MnrxIHLwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5dc237a-c9e6-4ea4-9030-2b11f4a6be1e"
      },
      "source": [
        "notes_for_instruments_validation = []\n",
        "for i,file in enumerate(glob.glob(current_path+\"midi_songs/validation/*.mid\")):\n",
        "      midi = converter.parse(file)\n",
        "      print('Parsing file ', i, \" \", file)\n",
        "      notes_to_parse = None\n",
        "      try:  # file has instrument parts\n",
        "          s2 = instrument.partitionByInstrument(midi)\n",
        "          notes_to_parse = s2.recurse()\n",
        "      except:  # file has notes in a flat structure\n",
        "          notes_to_parse = midi.flat.notes\n",
        "      notes_instrument = []\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes_instrument.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes_instrument.append('.'.join(str(n) for n in element.normalOrder))\n",
        "      notes_for_instruments_validation.append(notes_instrument)\n",
        "with open(current_path + 'VALIDATION_notes_for_instruments', 'wb') as filepath:\n",
        "    pickle.dump(notes_for_instruments_validation, filepath)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing file  0   /content/drive/My Drive/ISPR_project/midi_songs/validation/Crazy Little Thing Called Love.mid\n",
            "Parsing file  1   /content/drive/My Drive/ISPR_project/midi_songs/validation/Nothing Else Matters.2.mid\n",
            "Parsing file  2   /content/drive/My Drive/ISPR_project/midi_songs/validation/King Nothing.1.mid\n",
            "Parsing file  3   /content/drive/My Drive/ISPR_project/midi_songs/validation/Fixxxer.mid\n",
            "Parsing file  4   /content/drive/My Drive/ISPR_project/midi_songs/validation/Motorbreath.mid\n",
            "Parsing file  5   /content/drive/My Drive/ISPR_project/midi_songs/validation/Porch.mid\n",
            "Parsing file  6   /content/drive/My Drive/ISPR_project/midi_songs/validation/A Kind of Magic.mid\n",
            "Parsing file  7   /content/drive/My Drive/ISPR_project/midi_songs/validation/Don't Chain My Heart.mid\n",
            "Parsing file  8   /content/drive/My Drive/ISPR_project/midi_songs/validation/Se tornerai.1.mid\n",
            "Parsing file  9   /content/drive/My Drive/ISPR_project/midi_songs/validation/Pamela.1.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr4zRlBMf-f5"
      },
      "source": [
        "with open(current_path + 'POP_ROCK_notes_for_instruments', 'rb') as f:\n",
        "    notes_for_instruments = pickle.load(f)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pmIFIu9f-4K"
      },
      "source": [
        "with open(current_path + 'POP_ROCK_VALIDATION_notes_for_instruments', 'rb') as f:\n",
        "    notes_for_instruments_validation = pickle.load(f)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeZdfZ1jT530"
      },
      "source": [
        "with open(current_path + 'notes_for_instruments', 'rb') as f:\n",
        "    full_notes_for_instruments = pickle.load(f)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXvRSSm8T533"
      },
      "source": [
        "with open(current_path + 'VALIDATION_notes_for_instruments', 'rb') as f:\n",
        "    full_notes_for_instruments_validation = pickle.load(f)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuHePM_3dMXM"
      },
      "source": [
        "I obtain the number of different notes in our dataset, because this will be the **number of possible output classes**  of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEiySfEnTzyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ce0b8c-6270-4a48-b9ee-a131ee812544"
      },
      "source": [
        "# Count different possible outputs\n",
        "print(len(set(item for notes_for_instrument in notes_for_instruments for item in notes_for_instrument)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khLas76ZHecL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4636df4b-ed80-4936-9de1-df666b54c9a6"
      },
      "source": [
        "# Count different possible outputs valifation\n",
        "print(len(set(item for notes_for_instrument in notes_for_instruments_validation for item in notes_for_instrument)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-mABhgUnTcV"
      },
      "source": [
        "**Preprocess data** \\\\\n",
        "Now, there is some **data processing** that I have to do:\n",
        "\n",
        "- I will map each pitch or chord to an integer\n",
        "- I will create pairs of input sequences and its corresponding output note\n",
        "\n",
        "I can try different **sequence_length** to obtain different results. In this first version, I will use a sequence_length of 100.\n",
        "\n",
        "The network will made its prediction of the next note (or chord), based on the previous *sequence_length* notes (or chords). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkq3qb-hLra"
      },
      "source": [
        "# get all pitch names\n",
        "pitchnames_training = set(item for notes_for_instrument in full_notes_for_instruments for item in notes_for_instrument)\n",
        "pitchnames_validation = set(item for notes_for_instrument in full_notes_for_instruments_validation for item in notes_for_instrument)\n",
        "pitchnames = sorted(pitchnames_training.union(pitchnames_validation))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFVChPCk-enO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b56f0f-95f9-40a8-8957-52c99b091b42"
      },
      "source": [
        "n_vocab = len(pitchnames)\n",
        "n_vocab"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4PpfIFRnWIA"
      },
      "source": [
        "# create a dictionary to map pitches to integers\n",
        "note_to_int = defaultdict(int)\n",
        "note_to_int.update(dict((note, number) for number, note in enumerate(pitchnames)))\n",
        "network_input = []\n",
        "for notes in notes_for_instruments:\n",
        "    if len(notes) - sequence_length<=0:\n",
        "        print(\"canzone troppo corta\")\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "      # Map pitches of sequence_in to integers\n",
        "      network_input.append([note_to_int[char] for char in notes[i:i + sequence_length]])\n",
        "n_patterns = len(network_input)\n",
        "# reshape the input into a format compatible with Transormer layers\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QIDFrdeIIz1"
      },
      "source": [
        "# create a dictionary to map pitches to integers\n",
        "note_to_int_validation = defaultdict(int)\n",
        "note_to_int_validation.update(dict((notes_validation, number) for number, notes_validation in enumerate(pitchnames)))\n",
        "network_input_validation = []\n",
        "network_output_validation = []\n",
        "for notes_validation in notes_for_instruments_validation:\n",
        "    if len(notes_validation) - sequence_length<=0:\n",
        "        print(\"canzone troppo corta\")\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes_validation) - sequence_length, 1):\n",
        "      # Map pitches of sequence_in to integers\n",
        "      network_input_validation.append([note_to_int_validation[char] for char in notes_validation[i:i + sequence_length]])\n",
        "n_patterns_validation = len(network_input_validation)\n",
        "# reshape the input into a format compatible with Transormer layers\n",
        "network_input_validation = np.reshape(network_input_validation, (n_patterns_validation, sequence_length))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRPauXUdq5Y"
      },
      "source": [
        "Let's see the new metwork_input size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8eQQMbxhUkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a785ce-25e7-4c07-cdc9-db6efe480d6f"
      },
      "source": [
        "network_input.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(215475, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-c9sz4Bo8eZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936c1071-395f-4d5d-9501-ab2e67bfa925"
      },
      "source": [
        "network_input_validation.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12065, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6--Wc8UXnVgY"
      },
      "source": [
        "**Design neural network architecture** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ztPAQsnb7T"
      },
      "source": [
        "def create_network(sequence_length, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = CompressiveTransformer(\n",
        "    num_tokens = n_vocab,\n",
        "    dim = sequence_length,\n",
        "    depth = 6,\n",
        "    seq_len = sequence_length,\n",
        "    mem_len = sequence_length,\n",
        "    cmem_len = 256,\n",
        "    cmem_ratio = 4,\n",
        "    memory_layers = [5,6],\n",
        "    gru_gated_residual = False\n",
        "    )\n",
        "\n",
        "    model = AutoregressiveWrapper(model)\n",
        "    model.cuda()\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nsNVMocnhNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e150be10-d482-4459-b0ea-e991bbe140f1"
      },
      "source": [
        "model = create_network(sequence_length,n_vocab)\n",
        "\n",
        "print(model)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AutoregressiveWrapper(\n",
            "  (net): CompressiveTransformer(\n",
            "    (token_emb): Embedding(839, 64)\n",
            "    (to_model_dim): Identity()\n",
            "    (to_logits): Sequential(\n",
            "      (0): Identity()\n",
            "      (1): Linear(in_features=64, out_features=839, bias=True)\n",
            "    )\n",
            "    (attn_layers): ModuleList(\n",
            "      (0): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ff_layers): ModuleList(\n",
            "      (0): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRKI1q5WjwcL"
      },
      "source": [
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "          yield data\n",
        "\n",
        "data_train = torch.from_numpy(network_input).cuda()\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=32) \n",
        "cycle_train_loader  = cycle(DataLoader(data_train, batch_size = data_train.shape[0]))\n",
        "num_batches=math.ceil(data_train.shape[0]/batch_size) # Total number of batches"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYgRHLRIy3C"
      },
      "source": [
        "#Validation\n",
        "data_validation = torch.from_numpy(network_input_validation).cuda()\n",
        "validation_loader = torch.utils.data.DataLoader(data_validation, batch_size=32) \n",
        "cycle_validation_loader  = cycle(DataLoader(data_validation, batch_size = data_validation.shape[0]))\n",
        "num_batches_val=math.ceil(data_validation.shape[0]/batch_size) # Total number of batches"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60il158kxfq"
      },
      "source": [
        "# optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbO-XA3Dfrd2"
      },
      "source": [
        "In case we want to use previously trained weights, to continue the training in the point we left it, we should load them into the model.\n",
        "\n",
        "This is very useful in Google Colaboratory, that usually kills the virtual machine that is executing the Jupyter notework after a certime amount of time. If this happens to you, you should have to look for the last weights file in your configured Drive account and use it to train the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjfQL_Ck_92a"
      },
      "source": [
        "# In case we want to use previously trained weights\n",
        "weights = \"model_best.pth.tar\"\n",
        "checkpoint = torch.load(\"/content/drive/MyDrive/ISPR_project/Transformer/model_best.pth.tar\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqX3PsrJkyNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c0925a-cf2c-4279-8cfe-69d7fe2f8c55"
      },
      "source": [
        "# training\n",
        "for i in tqdm.tqdm(range(0,epochs), mininterval=20., desc='training'):\n",
        "    model.train()\n",
        "    tot_loss = 0.0\n",
        "    is_best=0\n",
        "    best_loss_value=n_vocab\n",
        "    avg_loss_val=0\n",
        "    for mlm_loss, aux_loss, is_last in model(next(cycle_train_loader), max_batch_size = batch_size, return_loss = True):\n",
        "        loss = mlm_loss + aux_loss\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        tot_loss+=loss;\n",
        "\n",
        "        if is_last:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "    \n",
        "    if i % VALIDATE_EVERY == 0 or i==epochs-1:\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "          for loss_val, aux_loss_val, is_last_val in model(next(cycle_validation_loader), max_batch_size = batch_size, return_loss = True):\n",
        "            avg_loss_val+=loss_val/num_batches_val;\n",
        "\n",
        "            if is_last_val:\n",
        "              print(f'\\n validation loss: {avg_loss_val.item():.4f}')\n",
        "\n",
        "\n",
        "    avg_loss=tot_loss/num_batches\n",
        "\n",
        "    if i%5==0 or i==epochs-1:\n",
        "      if best_loss_value>avg_loss:\n",
        "        best_loss_value=avg_loss;\n",
        "        is_best=1\n",
        "\n",
        "      save_checkpoint({\n",
        "      'epoch': i,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict' : optimizer.state_dict(),\n",
        "      'loss':avg_loss.item(),\n",
        "     }, is_best, 'Tran_64_Checkpoint'+str(i)+'_'+\"{:.4f}\".format(avg_loss.item())+'.pth.tar')\n",
        "      is_best=0\n",
        "    print(f'\\n Epoch: {i} |Training loss: {avg_loss.item():.4f}')\n",
        "print('\\nTraining complete.')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " validation loss: 6.6688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 1/2000 [03:59<132:47:34, 239.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 0 |Training loss: 6.9132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 2/2000 [07:53<131:51:24, 237.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 1 |Training loss: 6.6697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 3/2000 [11:48<131:24:58, 236.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 2 |Training loss: 6.4551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 4/2000 [15:45<131:23:32, 236.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 3 |Training loss: 6.2472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 5/2000 [19:43<131:25:04, 237.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 4 |Training loss: 6.0411\n",
            "\n",
            " validation loss: 5.6367\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 6/2000 [23:47<132:31:53, 239.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 5 |Training loss: 5.8452\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 7/2000 [27:45<132:19:21, 239.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 6 |Training loss: 5.6679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 8/2000 [31:44<132:11:59, 238.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 7 |Training loss: 5.5001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 9/2000 [35:43<132:08:10, 238.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 8 |Training loss: 5.3407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 10/2000 [39:42<132:11:14, 239.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 9 |Training loss: 5.1996\n",
            "\n",
            " validation loss: 4.8845\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 11/2000 [43:47<132:58:15, 240.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 10 |Training loss: 5.0697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 12/2000 [47:46<132:36:20, 240.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 11 |Training loss: 4.9429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 13/2000 [51:43<132:08:03, 239.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 12 |Training loss: 4.8252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 14/2000 [55:41<131:50:11, 238.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 13 |Training loss: 4.7235\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 15/2000 [59:40<131:44:03, 238.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 14 |Training loss: 4.6314\n",
            "\n",
            " validation loss: 4.4204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 16/2000 [1:03:43<132:23:59, 240.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 15 |Training loss: 4.5451\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 17/2000 [1:07:42<132:08:08, 239.88s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 16 |Training loss: 4.4688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 18/2000 [1:11:41<131:53:11, 239.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 17 |Training loss: 4.4028\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 19/2000 [1:15:40<131:38:43, 239.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 18 |Training loss: 4.3429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 20/2000 [1:19:39<131:31:26, 239.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 19 |Training loss: 4.2899\n",
            "\n",
            " validation loss: 4.1458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 21/2000 [1:23:42<132:10:17, 240.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 20 |Training loss: 4.2434\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 22/2000 [1:27:41<131:48:29, 239.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 21 |Training loss: 4.2002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 23/2000 [1:31:39<131:31:29, 239.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 22 |Training loss: 4.1586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 24/2000 [1:35:38<131:22:42, 239.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 23 |Training loss: 4.1187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 25/2000 [1:39:38<131:18:56, 239.36s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 24 |Training loss: 4.0804\n",
            "\n",
            " validation loss: 3.9658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 26/2000 [1:43:41<131:55:44, 240.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 25 |Training loss: 4.0444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 27/2000 [1:47:40<131:32:11, 240.01s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 26 |Training loss: 4.0107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 28/2000 [1:51:38<131:14:49, 239.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 27 |Training loss: 3.9786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 29/2000 [1:55:37<130:57:51, 239.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 28 |Training loss: 3.9474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 30/2000 [1:59:36<130:50:32, 239.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 29 |Training loss: 3.9167\n",
            "\n",
            " validation loss: 3.8155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 31/2000 [2:03:40<131:34:20, 240.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 30 |Training loss: 3.8868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 32/2000 [2:07:39<131:15:54, 240.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 31 |Training loss: 3.8574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 33/2000 [2:11:38<131:04:47, 239.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 32 |Training loss: 3.8287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 34/2000 [2:15:37<130:48:23, 239.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 33 |Training loss: 3.8008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 35/2000 [2:19:35<130:33:21, 239.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 34 |Training loss: 3.7734\n",
            "\n",
            " validation loss: 3.6868\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 36/2000 [2:23:39<131:13:39, 240.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 35 |Training loss: 3.7467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 37/2000 [2:27:37<130:43:29, 239.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 36 |Training loss: 3.7205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 38/2000 [2:31:35<130:22:21, 239.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 37 |Training loss: 3.6947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 39/2000 [2:35:33<130:12:07, 239.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 38 |Training loss: 3.6693\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 40/2000 [2:39:31<129:53:10, 238.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 39 |Training loss: 3.6446\n",
            "\n",
            " validation loss: 3.5786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 41/2000 [2:43:34<130:35:07, 239.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 40 |Training loss: 3.6203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 42/2000 [2:47:33<130:18:52, 239.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 41 |Training loss: 3.5964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 43/2000 [2:51:31<130:04:14, 239.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 42 |Training loss: 3.5734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 44/2000 [2:55:31<130:00:34, 239.28s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 43 |Training loss: 3.5513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 45/2000 [2:59:32<130:17:57, 239.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 44 |Training loss: 3.5298\n",
            "\n",
            " validation loss: 3.5021\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 46/2000 [3:03:36<130:49:15, 241.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 45 |Training loss: 3.5089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 47/2000 [3:07:35<130:26:06, 240.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 46 |Training loss: 3.4888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 48/2000 [3:11:33<130:05:43, 239.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 47 |Training loss: 3.4692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 49/2000 [3:15:32<129:50:22, 239.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 48 |Training loss: 3.4500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▎         | 50/2000 [3:19:31<129:36:10, 239.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 49 |Training loss: 3.4312\n",
            "\n",
            " validation loss: 3.4407\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 51/2000 [3:23:32<129:55:21, 239.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 50 |Training loss: 3.4127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 52/2000 [3:27:32<129:50:24, 239.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 51 |Training loss: 3.3946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 53/2000 [3:31:31<129:35:45, 239.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 52 |Training loss: 3.3770\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 54/2000 [3:35:29<129:19:04, 239.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 53 |Training loss: 3.3601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 55/2000 [3:39:26<128:54:27, 238.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 54 |Training loss: 3.3436\n",
            "\n",
            " validation loss: 3.3920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 56/2000 [3:43:28<129:21:50, 239.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 55 |Training loss: 3.3278\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 57/2000 [3:47:26<129:01:56, 239.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 56 |Training loss: 3.3122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 58/2000 [3:51:25<128:54:39, 238.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 57 |Training loss: 3.2968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 59/2000 [3:55:23<128:45:57, 238.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 58 |Training loss: 3.2820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 60/2000 [3:59:23<128:48:32, 239.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 59 |Training loss: 3.2673\n",
            "\n",
            " validation loss: 3.3475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 61/2000 [4:03:29<129:49:07, 241.03s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 60 |Training loss: 3.2528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 62/2000 [4:07:29<129:42:18, 240.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 61 |Training loss: 3.2391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 63/2000 [4:11:29<129:29:21, 240.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 62 |Training loss: 3.2250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 64/2000 [4:15:28<129:09:03, 240.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 63 |Training loss: 3.2119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 65/2000 [4:19:27<128:51:52, 239.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 64 |Training loss: 3.1986\n",
            "\n",
            " validation loss: 3.3149\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 66/2000 [4:23:31<129:26:05, 240.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 65 |Training loss: 3.1856\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 67/2000 [4:27:30<129:04:09, 240.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 66 |Training loss: 3.1732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 68/2000 [4:31:29<128:51:54, 240.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 67 |Training loss: 3.1601\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 69/2000 [4:35:29<128:40:27, 239.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 68 |Training loss: 3.1480\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 70/2000 [4:39:28<128:32:46, 239.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 69 |Training loss: 3.1358\n",
            "\n",
            " validation loss: 3.2876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 71/2000 [4:43:34<129:21:07, 241.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 70 |Training loss: 3.1237\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 72/2000 [4:47:36<129:24:28, 241.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 71 |Training loss: 3.1123\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 73/2000 [4:51:38<129:31:42, 241.98s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 72 |Training loss: 3.1009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 74/2000 [4:55:41<129:31:10, 242.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 73 |Training loss: 3.0895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 75/2000 [4:59:42<129:19:03, 241.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 74 |Training loss: 3.0790\n",
            "\n",
            " validation loss: 3.2685\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 76/2000 [5:03:49<130:08:36, 243.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 75 |Training loss: 3.0675\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 77/2000 [5:07:50<129:38:22, 242.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 76 |Training loss: 3.0572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 78/2000 [5:11:52<129:24:08, 242.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 77 |Training loss: 3.0467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 79/2000 [5:15:53<129:05:33, 241.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 78 |Training loss: 3.0364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 80/2000 [5:19:52<128:35:48, 241.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 79 |Training loss: 3.0266\n",
            "\n",
            " validation loss: 3.2537\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 81/2000 [5:24:00<129:38:32, 243.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 80 |Training loss: 3.0163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 82/2000 [5:28:03<129:29:11, 243.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 81 |Training loss: 3.0069\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 83/2000 [5:32:06<129:22:21, 242.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 82 |Training loss: 2.9972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 84/2000 [5:36:07<129:09:05, 242.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 83 |Training loss: 2.9879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 85/2000 [5:40:09<128:52:03, 242.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 84 |Training loss: 2.9788\n",
            "\n",
            " validation loss: 3.2446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 86/2000 [5:44:17<129:41:30, 243.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 85 |Training loss: 2.9692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 87/2000 [5:48:19<129:25:11, 243.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 86 |Training loss: 2.9607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 88/2000 [5:52:20<128:53:52, 242.69s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 87 |Training loss: 2.9512\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 89/2000 [5:56:20<128:19:26, 241.74s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 88 |Training loss: 2.9425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 90/2000 [6:00:20<128:04:29, 241.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 89 |Training loss: 2.9338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 91/2000 [6:04:25<128:31:19, 242.37s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " validation loss: 3.2403\n",
            "\n",
            " Epoch: 90 |Training loss: 2.9249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 92/2000 [6:08:25<128:03:08, 241.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 91 |Training loss: 2.9174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 93/2000 [6:12:25<127:44:54, 241.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 92 |Training loss: 2.9077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 94/2000 [6:16:24<127:21:59, 240.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 93 |Training loss: 2.9007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 95/2000 [6:20:24<127:16:37, 240.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 94 |Training loss: 2.8913\n",
            "\n",
            " validation loss: 3.2306\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 96/2000 [6:24:29<127:55:21, 241.87s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 95 |Training loss: 2.8854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAgrzFyRn3uq"
      },
      "source": [
        "**Music generation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFbSthkLUwmx"
      },
      "source": [
        "# In case we want to use previously trained weights\n",
        "weights = \"model_best.pth.tar\"\n",
        "checkpoint = torch.load(output_dir+weights)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WtYEXpyoPPK"
      },
      "source": [
        "# Generate network input again\n",
        "network_input_generation = []\n",
        "for notes in notes_for_instruments:\n",
        "    if len(notes) - sequence_length<=0:\n",
        "        print(\"canzone troppo corta\")\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "      network_input_generation.append([note_to_int[char] for char in notes[i:i + sequence_length]])\n",
        "n_patterns_generation = len(network_input_generation)\n",
        "network_input_generation = np.reshape(network_input, (n_patterns, sequence_length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuUGi5rVgbJQ"
      },
      "source": [
        "The workflow now is:\n",
        "\n",
        "\n",
        "1.   Pick a **seed sequence** randomly from your list of inputs (*pattern* variable)\n",
        "2.   Pass it as input for your model to generate a new element (note or chord)\n",
        "3.   Add the new element to your final song and to your *pattern* list\n",
        "4.   Remove the first item from *pattern*\n",
        "5.   Go to step 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_CEMQ84PszX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94143dd7-5c10-4a40-d64b-90c61ad44deb"
      },
      "source": [
        "network_input_generation.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(366889, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUTEiS0NXtkl"
      },
      "source": [
        "\"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "# pick a random sequence from the input as a starting point for the prediction\n",
        "start = np.random.randint(0, len(network_input)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "pattern = torch.from_numpy(network_input[start]).cuda()\n",
        "\n",
        "prediction_output = model.generate(pattern, 500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUlgtok68w-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d572bcc-973b-4027-e9a1-ab3efd5df710"
      },
      "source": [
        "result_sample=[]\n",
        "\n",
        "for i in range(500):\n",
        "  print(i)\n",
        "  result = int_to_note[prediction_output[i].item()]\n",
        "  print('\\r', 'Predicted ', i, \" \",result, end='')\n",
        "  result_sample.append(result)\n",
        "\n",
        "prediction_output=result_sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "\r Predicted  0   31\n",
            "\r Predicted  1   32\n",
            "\r Predicted  2   10.03\n",
            "\r Predicted  3   B-34\n",
            "\r Predicted  4   G#45\n",
            "\r Predicted  5   B-46\n",
            "\r Predicted  6   3.87\n",
            "\r Predicted  7   E-48\n",
            "\r Predicted  8   F39\n",
            "\r Predicted  9   B-110\n",
            "\r Predicted  10   B-311\n",
            "\r Predicted  11   10.212\n",
            "\r Predicted  12   G#313\n",
            "\r Predicted  13   C#414\n",
            "\r Predicted  14   B-315\n",
            "\r Predicted  15   E-416\n",
            "\r Predicted  16   G#417\n",
            "\r Predicted  17   10.218\n",
            "\r Predicted  18   B-319\n",
            "\r Predicted  19   G#320\n",
            "\r Predicted  20   D421\n",
            "\r Predicted  21   F422\n",
            "\r Predicted  22   G423\n",
            "\r Predicted  23   B-324\n",
            "\r Predicted  24   B-325\n",
            "\r Predicted  25   B-326\n",
            "\r Predicted  26   G#327\n",
            "\r Predicted  27   B-328\n",
            "\r Predicted  28   E-429\n",
            "\r Predicted  29   3.830\n",
            "\r Predicted  30   B-331\n",
            "\r Predicted  31   2.532\n",
            "\r Predicted  32   G#433\n",
            "\r Predicted  33   E-434\n",
            "\r Predicted  34   B-335\n",
            "\r Predicted  35   B-336\n",
            "\r Predicted  36   B-337\n",
            "\r Predicted  37   E-438\n",
            "\r Predicted  38   E239\n",
            "\r Predicted  39   G340\n",
            "\r Predicted  40   10.241\n",
            "\r Predicted  41   B-342\n",
            "\r Predicted  42   3.643\n",
            "\r Predicted  43   F#444\n",
            "\r Predicted  44   G#345\n",
            "\r Predicted  45   G#346\n",
            "\r Predicted  46   10.047\n",
            "\r Predicted  47   E-448\n",
            "\r Predicted  48   B-449\n",
            "\r Predicted  49   G#450\n",
            "\r Predicted  50   B-251\n",
            "\r Predicted  51   8.0.352\n",
            "\r Predicted  52   3.7.1053\n",
            "\r Predicted  53   B-454\n",
            "\r Predicted  54   B-255\n",
            "\r Predicted  55   B-456\n",
            "\r Predicted  56   0.3.757\n",
            "\r Predicted  57   E-358\n",
            "\r Predicted  58   F459\n",
            "\r Predicted  59   F460\n",
            "\r Predicted  60   E-461\n",
            "\r Predicted  61   C#662\n",
            "\r Predicted  62   3.7.1063\n",
            "\r Predicted  63   3.7.1064\n",
            "\r Predicted  64   G#465\n",
            "\r Predicted  65   G#466\n",
            "\r Predicted  66   G#467\n",
            "\r Predicted  67   5.1068\n",
            "\r Predicted  68   3.869\n",
            "\r Predicted  69   E-570\n",
            "\r Predicted  70   B-471\n",
            "\r Predicted  71   F#472\n",
            "\r Predicted  72   A473\n",
            "\r Predicted  73   A474\n",
            "\r Predicted  74   F#475\n",
            "\r Predicted  75   E-476\n",
            "\r Predicted  76   D477\n",
            "\r Predicted  77   C478\n",
            "\r Predicted  78   G479\n",
            "\r Predicted  79   E-480\n",
            "\r Predicted  80   B-381\n",
            "\r Predicted  81   3.882\n",
            "\r Predicted  82   383\n",
            "\r Predicted  83   E-484\n",
            "\r Predicted  84   E-485\n",
            "\r Predicted  85   G#486\n",
            "\r Predicted  86   E387\n",
            "\r Predicted  87   C#488\n",
            "\r Predicted  88   3.889\n",
            "\r Predicted  89   B-490\n",
            "\r Predicted  90   B-391\n",
            "\r Predicted  91   B-392\n",
            "\r Predicted  92   F#493\n",
            "\r Predicted  93   C494\n",
            "\r Predicted  94   A395\n",
            "\r Predicted  95   G#496\n",
            "\r Predicted  96   G#497\n",
            "\r Predicted  97   C#498\n",
            "\r Predicted  98   C#499\n",
            "\r Predicted  99   B-4100\n",
            "\r Predicted  100   B-4101\n",
            "\r Predicted  101   G#4102\n",
            "\r Predicted  102   3.7.10103\n",
            "\r Predicted  103   B-3104\n",
            "\r Predicted  104   B-3105\n",
            "\r Predicted  105   B-3106\n",
            "\r Predicted  106   C4107\n",
            "\r Predicted  107   C4108\n",
            "\r Predicted  108   E4109\n",
            "\r Predicted  109   C4110\n",
            "\r Predicted  110   D4111\n",
            "\r Predicted  111   B-3112\n",
            "\r Predicted  112   3.7113\n",
            "\r Predicted  113   10.3114\n",
            "\r Predicted  114   E-3115\n",
            "\r Predicted  115   B-3116\n",
            "\r Predicted  116   C#4117\n",
            "\r Predicted  117   11.3118\n",
            "\r Predicted  118   E-4119\n",
            "\r Predicted  119   C4120\n",
            "\r Predicted  120   B-3121\n",
            "\r Predicted  121   B-3122\n",
            "\r Predicted  122   E-3123\n",
            "\r Predicted  123   B-3124\n",
            "\r Predicted  124   B-4125\n",
            "\r Predicted  125   B-4126\n",
            "\r Predicted  126   E3127\n",
            "\r Predicted  127   E-4128\n",
            "\r Predicted  128   3.7129\n",
            "\r Predicted  129   B-1130\n",
            "\r Predicted  130   6.11131\n",
            "\r Predicted  131   D2132\n",
            "\r Predicted  132   6.11133\n",
            "\r Predicted  133   F2134\n",
            "\r Predicted  134   F2135\n",
            "\r Predicted  135   6.11136\n",
            "\r Predicted  136   F2137\n",
            "\r Predicted  137   F2138\n",
            "\r Predicted  138   F2139\n",
            "\r Predicted  139   0.5140\n",
            "\r Predicted  140   0.5141\n",
            "\r Predicted  141   C2142\n",
            "\r Predicted  142   B1143\n",
            "\r Predicted  143   C2144\n",
            "\r Predicted  144   A4145\n",
            "\r Predicted  145   10.2.5146\n",
            "\r Predicted  146   10.11147\n",
            "\r Predicted  147   10.3148\n",
            "\r Predicted  148   10.3149\n",
            "\r Predicted  149   F4150\n",
            "\r Predicted  150   G4151\n",
            "\r Predicted  151   6.10152\n",
            "\r Predicted  152   4.10153\n",
            "\r Predicted  153   A4154\n",
            "\r Predicted  154   3.8.9155\n",
            "\r Predicted  155   G4156\n",
            "\r Predicted  156   E1157\n",
            "\r Predicted  157   4.10158\n",
            "\r Predicted  158   0.4.7159\n",
            "\r Predicted  159   B1160\n",
            "\r Predicted  160   E-3161\n",
            "\r Predicted  161   F4162\n",
            "\r Predicted  162   E-1163\n",
            "\r Predicted  163   B-4164\n",
            "\r Predicted  164   A4165\n",
            "\r Predicted  165   B-1166\n",
            "\r Predicted  166   B-2167\n",
            "\r Predicted  167   10.2.5168\n",
            "\r Predicted  168   F#2169\n",
            "\r Predicted  169   C5170\n",
            "\r Predicted  170   A1171\n",
            "\r Predicted  171   4.9172\n",
            "\r Predicted  172   C5173\n",
            "\r Predicted  173   5.9174\n",
            "\r Predicted  174   B-3175\n",
            "\r Predicted  175   A4176\n",
            "\r Predicted  176   10.2177\n",
            "\r Predicted  177   D4178\n",
            "\r Predicted  178   B-1179\n",
            "\r Predicted  179   B-1180\n",
            "\r Predicted  180   B-2181\n",
            "\r Predicted  181   6.11182\n",
            "\r Predicted  182   8.9183\n",
            "\r Predicted  183   6184\n",
            "\r Predicted  184   4.10185\n",
            "\r Predicted  185   4.10186\n",
            "\r Predicted  186   7.0187\n",
            "\r Predicted  187   B-2188\n",
            "\r Predicted  188   E-2189\n",
            "\r Predicted  189   B-1190\n",
            "\r Predicted  190   B1191\n",
            "\r Predicted  191   A3192\n",
            "\r Predicted  192   B-3193\n",
            "\r Predicted  193   B-3194\n",
            "\r Predicted  194   B-3195\n",
            "\r Predicted  195   B-3196\n",
            "\r Predicted  196   E-4197\n",
            "\r Predicted  197   E-4198\n",
            "\r Predicted  198   E-4199\n",
            "\r Predicted  199   2.6200\n",
            "\r Predicted  200   F3201\n",
            "\r Predicted  201   F3202\n",
            "\r Predicted  202   F3203\n",
            "\r Predicted  203   2.6204\n",
            "\r Predicted  204   G4205\n",
            "\r Predicted  205   F4206\n",
            "\r Predicted  206   B-3207\n",
            "\r Predicted  207   A4208\n",
            "\r Predicted  208   10.2.5209\n",
            "\r Predicted  209   B-2210\n",
            "\r Predicted  210   F4211\n",
            "\r Predicted  211   B-2212\n",
            "\r Predicted  212   B-1213\n",
            "\r Predicted  213   B-2214\n",
            "\r Predicted  214   F4215\n",
            "\r Predicted  215   10.11216\n",
            "\r Predicted  216   B-3217\n",
            "\r Predicted  217   5.10218\n",
            "\r Predicted  218   B-1219\n",
            "\r Predicted  219   11220\n",
            "\r Predicted  220   B-2221\n",
            "\r Predicted  221   2.5222\n",
            "\r Predicted  222   E-4223\n",
            "\r Predicted  223   5224\n",
            "\r Predicted  224   F3225\n",
            "\r Predicted  225   E-4226\n",
            "\r Predicted  226   10.3227\n",
            "\r Predicted  227   B-2228\n",
            "\r Predicted  228   3.7229\n",
            "\r Predicted  229   5.10230\n",
            "\r Predicted  230   D4231\n",
            "\r Predicted  231   F3232\n",
            "\r Predicted  232   B-2233\n",
            "\r Predicted  233   D4234\n",
            "\r Predicted  234   10.2.5235\n",
            "\r Predicted  235   F#2236\n",
            "\r Predicted  236   F3237\n",
            "\r Predicted  237   B-2238\n",
            "\r Predicted  238   A2239\n",
            "\r Predicted  239   10.3240\n",
            "\r Predicted  240   B-3241\n",
            "\r Predicted  241   C2242\n",
            "\r Predicted  242   C2243\n",
            "\r Predicted  243   E-4244\n",
            "\r Predicted  244   E-4245\n",
            "\r Predicted  245   10.11246\n",
            "\r Predicted  246   5.10247\n",
            "\r Predicted  247   F3248\n",
            "\r Predicted  248   B-1249\n",
            "\r Predicted  249   B-3250\n",
            "\r Predicted  250   E-4251\n",
            "\r Predicted  251   9.2252\n",
            "\r Predicted  252   2.7253\n",
            "\r Predicted  253   B-2254\n",
            "\r Predicted  254   F3255\n",
            "\r Predicted  255   10256\n",
            "\r Predicted  256   5.10257\n",
            "\r Predicted  257   G4258\n",
            "\r Predicted  258   F1259\n",
            "\r Predicted  259   5.9.0260\n",
            "\r Predicted  260   F#2261\n",
            "\r Predicted  261   5.6.9.0262\n",
            "\r Predicted  262   2.7263\n",
            "\r Predicted  263   F4264\n",
            "\r Predicted  264   2.7265\n",
            "\r Predicted  265   C5266\n",
            "\r Predicted  266   F1267\n",
            "\r Predicted  267   C5268\n",
            "\r Predicted  268   C5269\n",
            "\r Predicted  269   5.9.0270\n",
            "\r Predicted  270   C5271\n",
            "\r Predicted  271   5.6.9.0272\n",
            "\r Predicted  272   5.6.9.10.0273\n",
            "\r Predicted  273   C5274\n",
            "\r Predicted  274   F5275\n",
            "\r Predicted  275   10.2.5276\n",
            "\r Predicted  276   F5277\n",
            "\r Predicted  277   3.4.6278\n",
            "\r Predicted  278   C5279\n",
            "\r Predicted  279   F2280\n",
            "\r Predicted  280   C5281\n",
            "\r Predicted  281   10.11.2.5.6282\n",
            "\r Predicted  282   0.4.7283\n",
            "\r Predicted  283   C5284\n",
            "\r Predicted  284   4.6285\n",
            "\r Predicted  285   F4286\n",
            "\r Predicted  286   7287\n",
            "\r Predicted  287   C5288\n",
            "\r Predicted  288   C5289\n",
            "\r Predicted  289   F5290\n",
            "\r Predicted  290   F#2291\n",
            "\r Predicted  291   2.7292\n",
            "\r Predicted  292   7.10.2293\n",
            "\r Predicted  293   5294\n",
            "\r Predicted  294   F1295\n",
            "\r Predicted  295   6.10.11.1296\n",
            "\r Predicted  296   7.0297\n",
            " Predicted  297   F4298\n",
            " Predicted  298   5.6.9.0299\n",
            " Predicted  299   0.5300\n",
            " Predicted  300   F1301\n",
            " Predicted  301   6.11302\n",
            " Predicted  302   D5303\n",
            " Predicted  303   F4304\n",
            " Predicted  304   9.0305\n",
            " Predicted  305   F#2306\n",
            " Predicted  306   F4307\n",
            " Predicted  307   5.9.0308\n",
            " Predicted  308   F#2309\n",
            " Predicted  309   4.10310\n",
            " Predicted  310   0.5311\n",
            " Predicted  311   A4312\n",
            " Predicted  312   B-1313\n",
            " Predicted  313   B-4314\n",
            " Predicted  314   C5315\n",
            " Predicted  315   6.11316\n",
            " Predicted  316   C2317\n",
            " Predicted  317   F#2318\n",
            " Predicted  318   F5319\n",
            " Predicted  319   F#2320\n",
            " Predicted  320   C5321\n",
            " Predicted  321   9.0322\n",
            " Predicted  322   D5323\n",
            " Predicted  323   2.7324\n",
            " Predicted  324   D5325\n",
            " Predicted  325   9.0326\n",
            " Predicted  326   F4327\n",
            " Predicted  327   5.9.0328\n",
            " Predicted  328   C5329\n",
            " Predicted  329   D5330\n",
            " Predicted  330   C5331\n",
            " Predicted  331   7.11332\n",
            " Predicted  332   E5333\n",
            " Predicted  333   7.11.0334\n",
            " Predicted  334   G1335\n",
            " Predicted  335   D5336\n",
            " Predicted  336   7.11.2337\n",
            " Predicted  337   G4338\n",
            " Predicted  338   G4339\n",
            " Predicted  339   G4340\n",
            " Predicted  340   C5341\n",
            " Predicted  341   7342\n",
            " Predicted  342   C5343\n",
            " Predicted  343   10.2.5344\n",
            " Predicted  344   D5345\n",
            " Predicted  345   D5346\n",
            " Predicted  346   2.5.9347\n",
            " Predicted  347   0.4348\n",
            " Predicted  348   9.0.4349\n",
            " Predicted  349   C4350\n",
            " Predicted  350   5351\n",
            " Predicted  351   A4352\n",
            " Predicted  352   5.9.0353\n",
            " Predicted  353   F4354\n",
            " Predicted  354   G2355\n",
            " Predicted  355   E2356\n",
            " Predicted  356   E2357\n",
            " Predicted  357   G2358\n",
            " Predicted  358   D5359\n",
            " Predicted  359   5360\n",
            " Predicted  360   9.0.2.5361\n",
            " Predicted  361   G4362\n",
            " Predicted  362   C5363\n",
            " Predicted  363   0.4364\n",
            " Predicted  364   A3365\n",
            " Predicted  365   A4366\n",
            " Predicted  366   9.11367\n",
            " Predicted  367   9.11368\n",
            " Predicted  368   A3369\n",
            " Predicted  369   5.9.0370\n",
            " Predicted  370   C5371\n",
            " Predicted  371   F2372\n",
            " Predicted  372   5.9.0373\n",
            " Predicted  373   C5374\n",
            " Predicted  374   F4375\n",
            " Predicted  375   9.0376\n",
            " Predicted  376   9.0377\n",
            " Predicted  377   F#2378\n",
            " Predicted  378   B-1379\n",
            " Predicted  379   F#2380\n",
            " Predicted  380   B-4381\n",
            " Predicted  381   9382\n",
            " Predicted  382   C5383\n",
            " Predicted  383   5.9.0384\n",
            " Predicted  384   D5385\n",
            " Predicted  385   E5386\n",
            " Predicted  386   D5387\n",
            " Predicted  387   D5388\n",
            " Predicted  388   E5389\n",
            " Predicted  389   D5390\n",
            " Predicted  390   C5391\n",
            " Predicted  391   C5392\n",
            " Predicted  392   C5393\n",
            " Predicted  393   E5394\n",
            " Predicted  394   C5395\n",
            " Predicted  395   C5396\n",
            " Predicted  396   C5397\n",
            " Predicted  397   C5398\n",
            " Predicted  398   C5399\n",
            " Predicted  399   C5400\n",
            " Predicted  400   C5401\n",
            " Predicted  401   D5402\n",
            " Predicted  402   7.11403\n",
            " Predicted  403   B4404\n",
            " Predicted  404   2.7405\n",
            " Predicted  405   F5406\n",
            " Predicted  406   D5407\n",
            " Predicted  407   C5408\n",
            " Predicted  408   D5409\n",
            " Predicted  409   7.11.2410\n",
            " Predicted  410   7411\n",
            " Predicted  411   F#5412\n",
            " Predicted  412   2.7413\n",
            " Predicted  413   B4414\n",
            " Predicted  414   D5415\n",
            " Predicted  415   D5416\n",
            " Predicted  416   C5417\n",
            " Predicted  417   C5418\n",
            " Predicted  418   B4419\n",
            " Predicted  419   D5420\n",
            " Predicted  420   C5421\n",
            " Predicted  421   B-4422\n",
            " Predicted  422   G3423\n",
            " Predicted  423   B4424\n",
            " Predicted  424   B4425\n",
            " Predicted  425   B4426\n",
            " Predicted  426   A4427\n",
            " Predicted  427   G4428\n",
            " Predicted  428   G4429\n",
            " Predicted  429   A4430\n",
            " Predicted  430   A4431\n",
            " Predicted  431   A4432\n",
            " Predicted  432   0.5433\n",
            " Predicted  433   A4434\n",
            " Predicted  434   A4435\n",
            " Predicted  435   C5436\n",
            " Predicted  436   A4437\n",
            " Predicted  437   A4438\n",
            " Predicted  438   C5439\n",
            " Predicted  439   C5440\n",
            " Predicted  440   B4441\n",
            " Predicted  441   C5442\n",
            " Predicted  442   C5443\n",
            " Predicted  443   C5444\n",
            " Predicted  444   4.7445\n",
            " Predicted  445   F2446\n",
            " Predicted  446   C5447\n",
            " Predicted  447   C5448\n",
            " Predicted  448   C5449\n",
            " Predicted  449   5.7450\n",
            " Predicted  450   6.9451\n",
            " Predicted  451   G4452\n",
            " Predicted  452   4.6453\n",
            " Predicted  453   D4454\n",
            " Predicted  454   6.9455\n",
            " Predicted  455   D4456\n",
            " Predicted  456   E2457\n",
            " Predicted  457   F#2458\n",
            " Predicted  458   4.6459\n",
            " Predicted  459   B1460\n",
            " Predicted  460   9.11.2461\n",
            " Predicted  461   0462\n",
            " Predicted  462   11.1463\n",
            " Predicted  463   F#2464\n",
            " Predicted  464   C4465\n",
            " Predicted  465   F#2466\n",
            " Predicted  466   A4467\n",
            " Predicted  467   4.6468\n",
            " Predicted  468   7.9469\n",
            " Predicted  469   2.6470\n",
            " Predicted  470   0.4471\n",
            " Predicted  471   F#4472\n",
            " Predicted  472   7.0473\n",
            " Predicted  473   F#2474\n",
            " Predicted  474   F#2475\n",
            " Predicted  475   A2476\n",
            " Predicted  476   9.11477\n",
            " Predicted  477   2.6478\n",
            " Predicted  478   9.11479\n",
            " Predicted  479   9.11480\n",
            " Predicted  480   2.6481\n",
            " Predicted  481   2.7482\n",
            " Predicted  482   B1483\n",
            " Predicted  483   B-2484\n",
            " Predicted  484   D4485\n",
            " Predicted  485   F#2486\n",
            " Predicted  486   9.2487\n",
            " Predicted  487   2.5488\n",
            " Predicted  488   A3489\n",
            " Predicted  489   D5490\n",
            " Predicted  490   2491\n",
            " Predicted  491   D4492\n",
            " Predicted  492   9.2493\n",
            " Predicted  493   D4494\n",
            " Predicted  494   F#2495\n",
            " Predicted  495   9.11496\n",
            " Predicted  496   F#2497\n",
            " Predicted  497   B1498\n",
            " Predicted  498   F#2499\n",
            " Predicted  499   D5"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lp5WcPlghe5"
      },
      "source": [
        "The last step is creating a MIDI file from the predictions.\n",
        "\n",
        "**music21** will help us again for this task. We should create a **Stream** and add to it the predicted notes and chords.\n",
        "\n",
        "We are adding an offset of 0.5 between elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7xYCPULXwV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0c21f4b-dd76-486a-89d7-ea8b84c067dd"
      },
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in prediction_output:\n",
        "    # pattern is a chord\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_output.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}