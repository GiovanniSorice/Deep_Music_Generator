{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generation_Transformer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Deep_Music_Generator/blob/main/notebooks/Music_Generation_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ3GwlYmvNT"
      },
      "source": [
        "# Transformer Music Generator "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNwQUwLIm7oW"
      },
      "source": [
        "\n",
        "\n",
        "In this notebook, we use an Transformer to generate some music.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFVGA5D4azA4"
      },
      "source": [
        "**This notebook was inspired (and part of the code comes from it) by [Music_Generation_LSTM](https://colab.research.google.com/drive/19TQqekOlnOSW36VCL8CPVEQKBBukmaEQ#scrollTo=DDOBVWULXfpz)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmj0efInB_L"
      },
      "source": [
        "\n",
        "\n",
        "**Load dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_tzJeReygOv"
      },
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsb9kaJmWHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f950eaed-0b1f-4eb4-9231-58dfd9f84ea4"
      },
      "source": [
        "pip install compressive_transformer_pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting compressive_transformer_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/30/39/b8caf2671abcb8615977c08766aa9f450addd6949f57c7dda87224e844b5/compressive_transformer_pytorch-0.3.20-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from compressive_transformer_pytorch) (1.7.0+cu101)\n",
            "Collecting mogrifier\n",
            "  Downloading https://files.pythonhosted.org/packages/77/01/62a55d0f8048e788fce435f2ade6478f443e4e53ed9b89b55ba0fc42c198/mogrifier-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (3.7.4.3)\n",
            "Installing collected packages: mogrifier, compressive-transformer-pytorch\n",
            "Successfully installed compressive-transformer-pytorch-0.3.20 mogrifier-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mi6KoBmX44A"
      },
      "source": [
        "import torch\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from compressive_transformer_pytorch import CompressiveTransformer\n",
        "from compressive_transformer_pytorch import AutoregressiveWrapper\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import pickle\n",
        "from music21 import converter, instrument, stream, note, chord\n",
        "import math\n",
        "import shutil\n",
        "from collections import defaultdict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwF2wx4oRZXW"
      },
      "source": [
        "# Set to false if you are not running\n",
        "# this notebook in Google Colaboratory\n",
        "run_on_colab = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2w9a2MknGmP"
      },
      "source": [
        "**Set hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnnLeO8Emsx3"
      },
      "source": [
        "# output directory name:\n",
        "output_dir = '/content/drive/My Drive/ISPR_project/Transformer/full_drop/'\n",
        "current_path ='/content/drive/My Drive/ISPR_project/'\n",
        "# training:\n",
        "epochs = 2000\n",
        "batch_size = 64\n",
        "learning_rate=1e-3\n",
        "# vector-space embedding: \n",
        "n_dim = 64 \n",
        "sequence_length = 64\n",
        "\n",
        "\n",
        "VALIDATE_EVERY  = 5\n",
        "\n",
        "GENERATE_EVERY  = 500\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUFOx5yB39xx"
      },
      "source": [
        "**Save model function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQHDRGj838-0"
      },
      "source": [
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, output_dir+filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(output_dir+filename, output_dir+'model_best.pth.tar')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvBjPl0cbI0_"
      },
      "source": [
        "**Google drive configuration (only Colab)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYmd3FoQq-Ri",
        "outputId": "b5f30036-49d6-4529-e2dd-81bdbd46114b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jan 17 09:23:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKil2p6sM2gZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "588a23f0-f6af-46e3-8690-d1484a75a1d8"
      },
      "source": [
        "if(run_on_colab):\n",
        "  from google.colab import drive\n",
        "  # This will prompt for authorization.\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU3gQinYmutQ"
      },
      "source": [
        "**Load data** \\\\\n",
        "Original MIDI files\n",
        " I have obtained  **MIDI files** from [The Lakh MIDI Dataset v0.1](https://colinraffel.com/projects/lmd/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wavgJZNpcR_f"
      },
      "source": [
        "## Processing data\n",
        "\n",
        "Let's process the files, and load them into **music21**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vILKBwYIcOvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f63261-eead-4697-df5e-8717a2f926fd"
      },
      "source": [
        "file = current_path+\"midi_songs/dataset/Metal/Metallica/Am I Evil?.mid\"\n",
        "midi = converter.parse(file)\n",
        "notes_to_parse = midi.flat.notes\n",
        "for element in notes_to_parse[:10]:\n",
        "  print(element, element.offset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<music21.chord.Chord E2 E3 B3 E4> 0.0\n",
            "<music21.chord.Chord E2 E3 B3 E4> 0.0\n",
            "<music21.note.Note E> 0.0\n",
            "<music21.chord.Chord C2 C#3> 0.0\n",
            "<music21.note.Note G#> 2.0\n",
            "<music21.chord.Chord D3 A3 D4> 3.0\n",
            "<music21.chord.Chord D3 A3 D4> 3.0\n",
            "<music21.note.Note D> 3.0\n",
            "<music21.chord.Chord C#3 C2> 3.0\n",
            "<music21.chord.Chord B3 E3 E4> 3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjyrXfKic2kI"
      },
      "source": [
        "I will process all MIDI files obtaining data from each note of chord.\n",
        "\n",
        "- If I process a **note**, I will store in the list a string representing the pitch (the note name) and the octave.\n",
        "\n",
        "- If I process a **chord** (Remember that chords are set of notes that are played at the same time) I will store a different type of string with numbers separated by dots. Each number represents the pitch of a chord note. \n",
        "\n",
        "As you can see, **I are not considering yet time offsets of each element**. In this first version, we won't consider them, so all the notes and chords will have the same duration. Maybe, in the future, I will consider them.\n",
        "\n",
        "I are creating a big list with all the elements of all the compositions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawbQHYVTOFM"
      },
      "source": [
        "notes_for_instruments = []\n",
        "for i,file in enumerate(glob.glob(current_path+\"midi_songs/dataset/*/*/*.mid\")):\n",
        "      midi = converter.parse(file)\n",
        "      print('Parsing file ', i, \" \", file)\n",
        "      notes_to_parse = None\n",
        "      try:  # file has instrument parts\n",
        "          s2 = instrument.partitionByInstrument(midi)\n",
        "          notes_to_parse = s2.recurse()\n",
        "      except:  # file has notes in a flat structure\n",
        "          notes_to_parse = midi.flat.notes\n",
        "      notes_instrument = []\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes_instrument.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes_instrument.append('.'.join(str(n) for n in element.normalOrder))\n",
        "      notes_for_instruments.append(notes_instrument)\n",
        "with open(current_path + 'notes_for_instruments', 'wb') as filepath:\n",
        "    pickle.dump(notes_for_instruments, filepath)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj7MnrxIHLwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5dc237a-c9e6-4ea4-9030-2b11f4a6be1e"
      },
      "source": [
        "notes_for_instruments_validation = []\n",
        "for i,file in enumerate(glob.glob(current_path+\"midi_songs/validation/*.mid\")):\n",
        "      midi = converter.parse(file)\n",
        "      print('Parsing file ', i, \" \", file)\n",
        "      notes_to_parse = None\n",
        "      try:  # file has instrument parts\n",
        "          s2 = instrument.partitionByInstrument(midi)\n",
        "          notes_to_parse = s2.recurse()\n",
        "      except:  # file has notes in a flat structure\n",
        "          notes_to_parse = midi.flat.notes\n",
        "      notes_instrument = []\n",
        "      for element in notes_to_parse:\n",
        "          if isinstance(element, note.Note):\n",
        "              notes_instrument.append(str(element.pitch))\n",
        "          elif isinstance(element, chord.Chord):\n",
        "              notes_instrument.append('.'.join(str(n) for n in element.normalOrder))\n",
        "      notes_for_instruments_validation.append(notes_instrument)\n",
        "with open(current_path + 'VALIDATION_notes_for_instruments', 'wb') as filepath:\n",
        "    pickle.dump(notes_for_instruments_validation, filepath)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parsing file  0   /content/drive/My Drive/ISPR_project/midi_songs/validation/Crazy Little Thing Called Love.mid\n",
            "Parsing file  1   /content/drive/My Drive/ISPR_project/midi_songs/validation/Nothing Else Matters.2.mid\n",
            "Parsing file  2   /content/drive/My Drive/ISPR_project/midi_songs/validation/King Nothing.1.mid\n",
            "Parsing file  3   /content/drive/My Drive/ISPR_project/midi_songs/validation/Fixxxer.mid\n",
            "Parsing file  4   /content/drive/My Drive/ISPR_project/midi_songs/validation/Motorbreath.mid\n",
            "Parsing file  5   /content/drive/My Drive/ISPR_project/midi_songs/validation/Porch.mid\n",
            "Parsing file  6   /content/drive/My Drive/ISPR_project/midi_songs/validation/A Kind of Magic.mid\n",
            "Parsing file  7   /content/drive/My Drive/ISPR_project/midi_songs/validation/Don't Chain My Heart.mid\n",
            "Parsing file  8   /content/drive/My Drive/ISPR_project/midi_songs/validation/Se tornerai.1.mid\n",
            "Parsing file  9   /content/drive/My Drive/ISPR_project/midi_songs/validation/Pamela.1.mid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr4zRlBMf-f5"
      },
      "source": [
        "with open(current_path + 'notes_for_instruments', 'rb') as f:\n",
        "    notes_for_instruments = pickle.load(f)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pmIFIu9f-4K"
      },
      "source": [
        "with open(current_path + 'VALIDATION_notes_for_instruments', 'rb') as f:\n",
        "    notes_for_instruments_validation = pickle.load(f)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuHePM_3dMXM"
      },
      "source": [
        "I obtain the number of different notes in our dataset, because this will be the **number of possible output classes**  of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEiySfEnTzyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b0dae4-c6f3-4109-96cd-b965c18b676f"
      },
      "source": [
        "# Count different possible outputs\n",
        "print(len(set(item for notes_for_instrument in notes_for_instruments for item in notes_for_instrument)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khLas76ZHecL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85ada659-24b2-4485-cc47-515a8cc575a0"
      },
      "source": [
        "# Count different possible outputs validation\n",
        "print(len(set(item for notes_for_instrument in notes_for_instruments_validation for item in notes_for_instrument)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "229\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-mABhgUnTcV"
      },
      "source": [
        "**Preprocess data** \\\\\n",
        "Now, there is some **data processing** that I have to do:\n",
        "\n",
        "- I will map each pitch or chord to an integer\n",
        "- I will create pairs of input sequences and its corresponding output note\n",
        "\n",
        "I can try different **sequence_length** to obtain different results. In this first version, I will use a sequence_length of 100.\n",
        "\n",
        "The network will made its prediction of the next note (or chord), based on the previous *sequence_length* notes (or chords). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYkq3qb-hLra"
      },
      "source": [
        "# get all pitch names\n",
        "pitchnames_training = set(item for notes_for_instrument in notes_for_instruments for item in notes_for_instrument)\n",
        "pitchnames_validation = set(item for notes_for_instrument in notes_for_instruments_validation for item in notes_for_instrument)\n",
        "pitchnames = sorted(pitchnames_training.union(pitchnames_validation))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFVChPCk-enO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad401f55-a48a-46f8-f6cb-b9c242e9ca0e"
      },
      "source": [
        "n_vocab = len(pitchnames)\n",
        "n_vocab"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "839"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4PpfIFRnWIA"
      },
      "source": [
        "# create a dictionary to map pitches to integers\n",
        "note_to_int = defaultdict(int)\n",
        "note_to_int.update(dict((note, number) for number, note in enumerate(pitchnames)))\n",
        "network_input = []\n",
        "for notes in notes_for_instruments:\n",
        "    if len(notes) - sequence_length<=0:\n",
        "        print(\"canzone troppo corta\")\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for j in range(0, len(notes) - sequence_length, sequence_length//2):\n",
        "      for i in range(j, len(notes) - sequence_length, sequence_length):\n",
        "        # Map pitches of sequence_in to integers\n",
        "        network_input.append([note_to_int[char] for char in notes[i:i + sequence_length]])\n",
        "n_patterns = len(network_input)\n",
        "# reshape the input into a format compatible with Transormer layers\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QIDFrdeIIz1"
      },
      "source": [
        "# create a dictionary to map pitches to integers\n",
        "note_to_int_validation = defaultdict(int)\n",
        "note_to_int_validation.update(dict((notes_validation, number) for number, notes_validation in enumerate(pitchnames)))\n",
        "network_input_validation = []\n",
        "network_output_validation = []\n",
        "for notes_validation in notes_for_instruments_validation:\n",
        "    if len(notes_validation) - sequence_length<=0:\n",
        "        print(\"canzone troppo corta\")\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for j in range(0, len(notes_validation) - sequence_length, sequence_length//2):\n",
        "      for i in range(j, len(notes_validation) - sequence_length, sequence_length):\n",
        "        # Map pitches of sequence_in to integers\n",
        "        network_input_validation.append([note_to_int_validation[char] for char in notes_validation[i:i + sequence_length]])\n",
        "n_patterns_validation = len(network_input_validation)\n",
        "# reshape the input into a format compatible with Transormer layers\n",
        "network_input_validation = np.reshape(network_input_validation, (n_patterns_validation, sequence_length))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRPauXUdq5Y"
      },
      "source": [
        "Let's see the new network_input size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8eQQMbxhUkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c0f9c44-6d61-4432-ca62-ea5adc24ff12"
      },
      "source": [
        "network_input.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(402204, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-c9sz4Bo8eZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3854be67-f4cc-40ee-86da-6dd8c084417b"
      },
      "source": [
        "network_input_validation.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39753, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6--Wc8UXnVgY"
      },
      "source": [
        "**Design neural network architecture** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ztPAQsnb7T"
      },
      "source": [
        "def create_network(sequence_length, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = CompressiveTransformer(\n",
        "    num_tokens = n_vocab,\n",
        "    dim = sequence_length,\n",
        "    depth = 6,\n",
        "    seq_len = sequence_length,\n",
        "    mem_len = sequence_length,\n",
        "    cmem_len = 256,\n",
        "    cmem_ratio = 4,\n",
        "    memory_layers = [5,6],\n",
        "    gru_gated_residual = False,\n",
        "    attn_dropout = 0.1,            # dropout post-attention\n",
        "    ff_dropout = 0.1,              # dropout in feedforward\n",
        "    attn_layer_dropout = 0.1      # dropout for attention layer output\n",
        "    )\n",
        "\n",
        "    model = AutoregressiveWrapper(model)\n",
        "    model.cuda()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nsNVMocnhNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a5830e-9082-472d-f141-2995b5f6a196"
      },
      "source": [
        "model = create_network(sequence_length,n_vocab)\n",
        "\n",
        "print(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AutoregressiveWrapper(\n",
            "  (net): CompressiveTransformer(\n",
            "    (token_emb): Embedding(839, 64)\n",
            "    (to_model_dim): Identity()\n",
            "    (to_logits): Sequential(\n",
            "      (0): Identity()\n",
            "      (1): Linear(in_features=64, out_features=839, bias=True)\n",
            "    )\n",
            "    (attn_layers): ModuleList(\n",
            "      (0): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(64, 64, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=64, out_features=64, bias=False)\n",
            "            (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
            "            (to_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ff_layers): ModuleList(\n",
            "      (0): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (5): Residual(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=64, out_features=256, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "            (w2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRKI1q5WjwcL"
      },
      "source": [
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "          yield data\n",
        "\n",
        "data_train = torch.from_numpy(network_input).cuda()\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=32) \n",
        "cycle_train_loader  = cycle(DataLoader(data_train, batch_size = data_train.shape[0]))\n",
        "num_batches=math.ceil(data_train.shape[0]/batch_size) # Total number of batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFYgRHLRIy3C"
      },
      "source": [
        "#Validation\n",
        "data_validation = torch.from_numpy(network_input_validation).cuda()\n",
        "validation_loader = torch.utils.data.DataLoader(data_validation, batch_size=32) \n",
        "cycle_validation_loader  = cycle(DataLoader(data_validation, batch_size = data_validation.shape[0]))\n",
        "num_batches_val=math.ceil(data_validation.shape[0]/batch_size) # Total number of batches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60il158kxfq"
      },
      "source": [
        "# optimizer\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbO-XA3Dfrd2"
      },
      "source": [
        "In case we want to use previously trained weights, to continue the training in the point we left it, we should load them into the model.\n",
        "\n",
        "This is very useful in Google Colaboratory, that usually kills the virtual machine that is executing the Jupyter notework after a certime amount of time. If this happens to you, you should have to look for the last weights file in your configured Drive account and use it to train the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjfQL_Ck_92a"
      },
      "source": [
        "# In case we want to use previously trained weights\n",
        "weights = \"model_best.pth.tar\"\n",
        "checkpoint = torch.load(output_dir + weights)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqX3PsrJkyNN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa0a685-cc02-411f-d3d2-9cd7146edf64"
      },
      "source": [
        "# training\n",
        "for i in tqdm.tqdm(range(606,epochs), mininterval=20., desc='training'):\n",
        "    model.train()\n",
        "    tot_loss = 0.0\n",
        "    is_best=0\n",
        "    best_loss_value=n_vocab\n",
        "    avg_loss_val=0\n",
        "    for mlm_loss, aux_loss, is_last in model(next(cycle_train_loader), max_batch_size = batch_size, return_loss = True):\n",
        "        loss = mlm_loss + aux_loss\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        tot_loss+=loss;\n",
        "\n",
        "        if is_last:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "    \n",
        "    if i % VALIDATE_EVERY == 0 or i==epochs-1:\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "          for loss_val, aux_loss_val, is_last_val in model(next(cycle_validation_loader), max_batch_size = batch_size, return_loss = True):\n",
        "            avg_loss_val+=loss_val/num_batches_val;\n",
        "\n",
        "            if is_last_val:\n",
        "              print(f'\\n validation loss: {avg_loss_val.item():.4f}')\n",
        "\n",
        "\n",
        "    avg_loss=tot_loss/num_batches\n",
        "\n",
        "    if i%5==0 or i==epochs-1:\n",
        "      if best_loss_value>avg_loss:\n",
        "        best_loss_value=avg_loss;\n",
        "        is_best=1\n",
        "\n",
        "      save_checkpoint({\n",
        "      'epoch': i,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict' : optimizer.state_dict(),\n",
        "      'loss':avg_loss.item(),\n",
        "     }, is_best, 'Tran_64_Checkpoint'+str(i)+'_'+\"{:.4f}\".format(avg_loss.item())+'.pth.tar')\n",
        "      is_best=0\n",
        "    print(f'\\n Epoch: {i} |Training loss: {avg_loss.item():.4f}')\n",
        "print('\\nTraining complete.')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training:   0%|          | 1/1394 [04:36<107:01:53, 276.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 606 |Training loss: 2.4825\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 2/1394 [09:13<106:58:30, 276.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 607 |Training loss: 2.4809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 3/1394 [13:48<106:42:04, 276.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 608 |Training loss: 2.4794\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 4/1394 [18:22<106:26:07, 275.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 609 |Training loss: 2.4781\n",
            "\n",
            " validation loss: 3.4291\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 5/1394 [23:06<107:18:47, 278.13s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 610 |Training loss: 2.4766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   0%|          | 6/1394 [27:45<107:18:07, 278.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 611 |Training loss: 2.4752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 7/1394 [32:21<106:54:49, 277.50s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 612 |Training loss: 2.4738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 8/1394 [36:56<106:33:24, 276.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 613 |Training loss: 2.4723\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 9/1394 [41:31<106:15:53, 276.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 614 |Training loss: 2.4711\n",
            "\n",
            " validation loss: 3.4295\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 10/1394 [46:14<107:02:03, 278.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 615 |Training loss: 2.4695\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 11/1394 [50:49<106:33:34, 277.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 616 |Training loss: 2.4680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 12/1394 [55:24<106:09:47, 276.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 617 |Training loss: 2.4667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 13/1394 [59:59<105:54:56, 276.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 618 |Training loss: 2.4652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 14/1394 [1:04:34<105:43:59, 275.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 619 |Training loss: 2.4640\n",
            "\n",
            " validation loss: 3.4302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 15/1394 [1:09:18<106:36:12, 278.30s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 620 |Training loss: 2.4622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 16/1394 [1:13:54<106:13:04, 277.49s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 621 |Training loss: 2.4611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|          | 17/1394 [1:18:28<105:49:41, 276.68s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 622 |Training loss: 2.4598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 18/1394 [1:23:06<105:48:43, 276.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 623 |Training loss: 2.4584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 19/1394 [1:27:41<105:35:43, 276.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 624 |Training loss: 2.4570\n",
            "\n",
            " validation loss: 3.4308\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   1%|▏         | 20/1394 [1:32:26<106:27:34, 278.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 625 |Training loss: 2.4556\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 21/1394 [1:37:01<105:59:12, 277.90s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 626 |Training loss: 2.4541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 22/1394 [1:41:36<105:33:09, 276.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 627 |Training loss: 2.4529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 23/1394 [1:46:11<105:15:49, 276.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 628 |Training loss: 2.4513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 24/1394 [1:50:46<104:59:55, 275.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 629 |Training loss: 2.4500\n",
            "\n",
            " validation loss: 3.4314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 25/1394 [1:55:30<105:51:01, 278.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 630 |Training loss: 2.4486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 26/1394 [2:00:05<105:24:55, 277.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 631 |Training loss: 2.4475\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 27/1394 [2:04:40<105:04:02, 276.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 632 |Training loss: 2.4461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 28/1394 [2:09:16<104:53:55, 276.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 633 |Training loss: 2.4447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 29/1394 [2:13:51<104:40:50, 276.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 634 |Training loss: 2.4435\n",
            "\n",
            " validation loss: 3.4323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 30/1394 [2:18:35<105:30:21, 278.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 635 |Training loss: 2.4421\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 31/1394 [2:23:11<105:06:44, 277.63s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 636 |Training loss: 2.4408\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 32/1394 [2:27:48<104:56:50, 277.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 637 |Training loss: 2.4395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 33/1394 [2:32:24<104:39:55, 276.85s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 638 |Training loss: 2.4381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   2%|▏         | 34/1394 [2:36:59<104:23:47, 276.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 639 |Training loss: 2.4369\n",
            "\n",
            " validation loss: 3.4327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 35/1394 [2:41:43<105:15:11, 278.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 640 |Training loss: 2.4359\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 36/1394 [2:46:19<104:47:29, 277.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 641 |Training loss: 2.4347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 37/1394 [2:51:02<105:19:06, 279.40s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 642 |Training loss: 2.4332\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 38/1394 [2:55:42<105:17:30, 279.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 643 |Training loss: 2.4319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 39/1394 [3:00:21<105:14:09, 279.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 644 |Training loss: 2.4305\n",
            "\n",
            " validation loss: 3.4335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 40/1394 [3:05:13<106:28:27, 283.09s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 645 |Training loss: 2.4294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 41/1394 [3:09:56<106:26:33, 283.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 646 |Training loss: 2.4279\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 42/1394 [3:14:39<106:19:44, 283.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 647 |Training loss: 2.4269\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 43/1394 [3:19:23<106:20:00, 283.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 648 |Training loss: 2.4254\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 44/1394 [3:24:07<106:16:50, 283.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 649 |Training loss: 2.4240\n",
            "\n",
            " validation loss: 3.4343\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 45/1394 [3:29:00<107:17:34, 286.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 650 |Training loss: 2.4231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 46/1394 [3:33:44<106:58:02, 285.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 651 |Training loss: 2.4217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 47/1394 [3:38:28<106:43:40, 285.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 652 |Training loss: 2.4203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   3%|▎         | 48/1394 [3:43:12<106:32:27, 284.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 653 |Training loss: 2.4189\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 49/1394 [3:47:57<106:23:16, 284.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 654 |Training loss: 2.4178\n",
            "\n",
            " validation loss: 3.4356\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 50/1394 [3:52:50<107:14:24, 287.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 655 |Training loss: 2.4167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 51/1394 [3:57:35<106:53:32, 286.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 656 |Training loss: 2.4153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▎         | 52/1394 [4:02:19<106:35:28, 285.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 657 |Training loss: 2.4140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 53/1394 [4:07:04<106:21:51, 285.54s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 658 |Training loss: 2.4128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 54/1394 [4:11:48<106:11:24, 285.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 659 |Training loss: 2.4113\n",
            "\n",
            " validation loss: 3.4365\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 55/1394 [4:16:43<107:09:27, 288.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 660 |Training loss: 2.4102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 56/1394 [4:21:26<106:32:07, 286.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 661 |Training loss: 2.4086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 57/1394 [4:26:08<105:56:39, 285.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 662 |Training loss: 2.4073\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 58/1394 [4:30:47<105:10:31, 283.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 663 |Training loss: 2.4062\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 59/1394 [4:35:28<104:44:41, 282.46s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 664 |Training loss: 2.4050\n",
            "\n",
            " validation loss: 3.4380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 60/1394 [4:40:20<105:45:52, 285.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 665 |Training loss: 2.4036\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 61/1394 [4:45:05<105:35:16, 285.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 666 |Training loss: 2.4023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   4%|▍         | 62/1394 [4:49:50<105:35:21, 285.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 667 |Training loss: 2.4009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 63/1394 [4:54:32<105:03:49, 284.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 668 |Training loss: 2.3998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 64/1394 [4:59:09<104:14:05, 282.14s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 669 |Training loss: 2.3984\n",
            "\n",
            " validation loss: 3.4392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 65/1394 [5:03:54<104:26:05, 282.89s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 670 |Training loss: 2.3973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining:   5%|▍         | 66/1394 [5:08:30<103:34:01, 280.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch: 671 |Training loss: 2.3961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAgrzFyRn3uq"
      },
      "source": [
        "**Music generation**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFbSthkLUwmx"
      },
      "source": [
        "# In case we want to use previously trained weights\n",
        "weights = \"model_best.pth.tar\"\n",
        "checkpoint = torch.load(output_dir+weights)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WtYEXpyoPPK"
      },
      "source": [
        "note_to_int = defaultdict(int)\n",
        "note_to_int.update(dict((note, number) for number, note in enumerate(pitchnames)))\n",
        "network_input = []\n",
        "\n",
        "# Generate network input again\n",
        "network_input_generation = []\n",
        "for notes in notes_for_instruments:\n",
        "    if len(notes) - sequence_length<=0:\n",
        "        print(\"canzone troppo corta\")\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "      network_input_generation.append([note_to_int[char] for char in notes[i:i + sequence_length]])\n",
        "n_patterns_generation = len(network_input_generation)\n",
        "network_input_generation = np.reshape(network_input_generation, (n_patterns_generation, sequence_length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuUGi5rVgbJQ"
      },
      "source": [
        "The workflow now is:\n",
        "\n",
        "\n",
        "1.   Pick a **seed sequence** randomly from your list of inputs (*pattern* variable)\n",
        "2.   Pass it as input for your model to generate a new element (note or chord)\n",
        "3.   Add the new element to your final song and to your *pattern* list\n",
        "4.   Remove the first item from *pattern*\n",
        "5.   Go to step 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_CEMQ84PszX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a210d2-237c-4de0-fa80-de81eb30c902"
      },
      "source": [
        "network_input_generation.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(366889, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUTEiS0NXtkl"
      },
      "source": [
        "\"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "# pick a random sequence from the input as a starting point for the prediction\n",
        "start = np.random.randint(0, len(network_input_generation)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "pattern = torch.from_numpy(network_input_generation[start]).cuda()\n",
        "\n",
        "prediction_output = model.generate(pattern, 500)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUlgtok68w-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ea481b-dda6-4c50-f668-2e72816899ce"
      },
      "source": [
        "result_sample=[]\n",
        "\n",
        "for i in range(500):\n",
        "  print(i)\n",
        "  result = int_to_note[prediction_output[i].item()]\n",
        "  print('\\r', 'Predicted ', i, \" \",result, end='')\n",
        "  result_sample.append(result)\n",
        "\n",
        "prediction_output=result_sample"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "\r Predicted  0   F#21\n",
            "\r Predicted  1   F#22\n",
            "\r Predicted  2   F#23\n",
            "\r Predicted  3   F#24\n",
            "\r Predicted  4   F#25\n",
            "\r Predicted  5   6.96\n",
            "\r Predicted  6   F#27\n",
            "\r Predicted  7   6.98\n",
            "\r Predicted  8   B29\n",
            "\r Predicted  9   F#210\n",
            "\r Predicted  10   6.911\n",
            "\r Predicted  11   6.912\n",
            "\r Predicted  12   C213\n",
            "\r Predicted  13   6.914\n",
            "\r Predicted  14   6.915\n",
            "\r Predicted  15   6.916\n",
            "\r Predicted  16   6.917\n",
            "\r Predicted  17   6.918\n",
            "\r Predicted  18   6.919\n",
            "\r Predicted  19   6.920\n",
            "\r Predicted  20   2.6.921\n",
            "\r Predicted  21   6.922\n",
            "\r Predicted  22   F#223\n",
            "\r Predicted  23   F#224\n",
            "\r Predicted  24   6.925\n",
            "\r Predicted  25   F#226\n",
            "\r Predicted  26   6.927\n",
            "\r Predicted  27   6.928\n",
            "\r Predicted  28   A429\n",
            "\r Predicted  29   6.930\n",
            "\r Predicted  30   6.931\n",
            "\r Predicted  31   F#232\n",
            "\r Predicted  32   A433\n",
            "\r Predicted  33   F#234\n",
            "\r Predicted  34   F#235\n",
            "\r Predicted  35   A436\n",
            "\r Predicted  36   6.937\n",
            "\r Predicted  37   2.638\n",
            "\r Predicted  38   6.939\n",
            "\r Predicted  39   6.940\n",
            "\r Predicted  40   6.941\n",
            "\r Predicted  41   2.642\n",
            "\r Predicted  42   6.943\n",
            "\r Predicted  43   6.944\n",
            "\r Predicted  44   F#245\n",
            "\r Predicted  45   6.946\n",
            "\r Predicted  46   C247\n",
            "\r Predicted  47   6.948\n",
            "\r Predicted  48   6.949\n",
            "\r Predicted  49   6.950\n",
            "\r Predicted  50   6.9.0.251\n",
            "\r Predicted  51   6.952\n",
            "\r Predicted  52   6.953\n",
            "\r Predicted  53   6.954\n",
            "\r Predicted  54   F#255\n",
            "\r Predicted  55   6.956\n",
            "\r Predicted  56   C257\n",
            "\r Predicted  57   6.958\n",
            "\r Predicted  58   6.959\n",
            "\r Predicted  59   6.960\n",
            "\r Predicted  60   A461\n",
            "\r Predicted  61   F#262\n",
            "\r Predicted  62   6.963\n",
            "\r Predicted  63   C#264\n",
            "\r Predicted  64   6.965\n",
            "\r Predicted  65   C266\n",
            "\r Predicted  66   6.967\n",
            "\r Predicted  67   6.968\n",
            "\r Predicted  68   6.969\n",
            "\r Predicted  69   10.170\n",
            "\r Predicted  70   771\n",
            "\r Predicted  71   6.9.072\n",
            "\r Predicted  72   973\n",
            "\r Predicted  73   A474\n",
            "\r Predicted  74   6.975\n",
            "\r Predicted  75   7.976\n",
            "\r Predicted  76   6.977\n",
            "\r Predicted  77   9.178\n",
            "\r Predicted  78   9.1079\n",
            "\r Predicted  79   6.980\n",
            "\r Predicted  80   C281\n",
            "\r Predicted  81   F#282\n",
            "\r Predicted  82   A483\n",
            "\r Predicted  83   A484\n",
            "\r Predicted  84   F#285\n",
            "\r Predicted  85   A486\n",
            "\r Predicted  86   F#287\n",
            "\r Predicted  87   6.988\n",
            "\r Predicted  88   A489\n",
            "\r Predicted  89   F#290\n",
            "\r Predicted  90   6.991\n",
            "\r Predicted  91   6.992\n",
            "\r Predicted  92   C293\n",
            "\r Predicted  93   6.994\n",
            "\r Predicted  94   6.995\n",
            "\r Predicted  95   A496\n",
            "\r Predicted  96   C297\n",
            "\r Predicted  97   F#298\n",
            "\r Predicted  98   F599\n",
            "\r Predicted  99   C2100\n",
            "\r Predicted  100   F#2101\n",
            "\r Predicted  101   A4102\n",
            "\r Predicted  102   F#2103\n",
            "\r Predicted  103   A4104\n",
            "\r Predicted  104   F#2105\n",
            "\r Predicted  105   A4106\n",
            "\r Predicted  106   F#2107\n",
            "\r Predicted  107   C2108\n",
            "\r Predicted  108   6.9109\n",
            "\r Predicted  109   6.9110\n",
            "\r Predicted  110   6.9111\n",
            "\r Predicted  111   6.9112\n",
            "\r Predicted  112   A4113\n",
            "\r Predicted  113   F#2114\n",
            "\r Predicted  114   6.9115\n",
            "\r Predicted  115   C2116\n",
            "\r Predicted  116   6.9117\n",
            "\r Predicted  117   6.9118\n",
            "\r Predicted  118   F#2119\n",
            "\r Predicted  119   F#2120\n",
            "\r Predicted  120   6.9121\n",
            "\r Predicted  121   6.9122\n",
            "\r Predicted  122   C2123\n",
            "\r Predicted  123   6.9124\n",
            "\r Predicted  124   6.9125\n",
            "\r Predicted  125   6.9126\n",
            "\r Predicted  126   F#2127\n",
            "\r Predicted  127   6.9128\n",
            "\r Predicted  128   6.9129\n",
            "\r Predicted  129   G#5130\n",
            "\r Predicted  130   6.9131\n",
            "\r Predicted  131   6.9132\n",
            "\r Predicted  132   A4133\n",
            "\r Predicted  133   6.9134\n",
            "\r Predicted  134   6.9135\n",
            "\r Predicted  135   C2136\n",
            "\r Predicted  136   6.9137\n",
            "\r Predicted  137   6.9138\n",
            "\r Predicted  138   11.4139\n",
            "\r Predicted  139   D2140\n",
            "\r Predicted  140   3.6141\n",
            "\r Predicted  141   F#2142\n",
            "\r Predicted  142   A4143\n",
            "\r Predicted  143   6.9144\n",
            "\r Predicted  144   6.9145\n",
            "\r Predicted  145   C2146\n",
            "\r Predicted  146   6.9147\n",
            "\r Predicted  147   C2148\n",
            "\r Predicted  148   6.9149\n",
            "\r Predicted  149   F#2150\n",
            "\r Predicted  150   F#2151\n",
            "\r Predicted  151   6.9152\n",
            "\r Predicted  152   G#2153\n",
            "\r Predicted  153   6.9154\n",
            "\r Predicted  154   6.9155\n",
            "\r Predicted  155   A4156\n",
            "\r Predicted  156   F#2157\n",
            "\r Predicted  157   6.9158\n",
            "\r Predicted  158   C2159\n",
            "\r Predicted  159   8.9160\n",
            "\r Predicted  160   6.9161\n",
            "\r Predicted  161   F#2162\n",
            "\r Predicted  162   6.9163\n",
            "\r Predicted  163   10.0164\n",
            "\r Predicted  164   6.9165\n",
            "\r Predicted  165   6.9166\n",
            "\r Predicted  166   A4167\n",
            "\r Predicted  167   6.9168\n",
            "\r Predicted  168   3.6169\n",
            "\r Predicted  169   F#2170\n",
            "\r Predicted  170   6.9171\n",
            "\r Predicted  171   F#4172\n",
            "\r Predicted  172   6.9173\n",
            "\r Predicted  173   6.9174\n",
            "\r Predicted  174   B4175\n",
            "\r Predicted  175   6.9176\n",
            "\r Predicted  176   6.9177\n",
            "\r Predicted  177   A4178\n",
            "\r Predicted  178   D4179\n",
            "\r Predicted  179   A4180\n",
            "\r Predicted  180   C2181\n",
            "\r Predicted  181   F#2182\n",
            "\r Predicted  182   C2183\n",
            "\r Predicted  183   6.9184\n",
            "\r Predicted  184   C2185\n",
            "\r Predicted  185   6.9186\n",
            "\r Predicted  186   6.9.0187\n",
            "\r Predicted  187   A5188\n",
            "\r Predicted  188   G4189\n",
            "\r Predicted  189   F#3190\n",
            "\r Predicted  190   6.9191\n",
            "\r Predicted  191   6.9192\n",
            "\r Predicted  192   E4193\n",
            "\r Predicted  193   E4194\n",
            "\r Predicted  194   G4195\n",
            "\r Predicted  195   E4196\n",
            "\r Predicted  196   E4197\n",
            "\r Predicted  197   E4198\n",
            "\r Predicted  198   E4199\n",
            "\r Predicted  199   E4200\n",
            "\r Predicted  200   E4201\n",
            "\r Predicted  201   E4202\n",
            "\r Predicted  202   D4203\n",
            "\r Predicted  203   E4204\n",
            "\r Predicted  204   G4205\n",
            "\r Predicted  205   A4206\n",
            "\r Predicted  206   5.9.0207\n",
            "\r Predicted  207   G3208\n",
            "\r Predicted  208   D3209\n",
            "\r Predicted  209   E4210\n",
            "\r Predicted  210   A3211\n",
            "\r Predicted  211   E4212\n",
            "\r Predicted  212   G1213\n",
            "\r Predicted  213   F#1214\n",
            "\r Predicted  214   E4215\n",
            "\r Predicted  215   E4216\n",
            "\r Predicted  216   C#4217\n",
            "\r Predicted  217   E4218\n",
            "\r Predicted  218   E4219\n",
            "\r Predicted  219   B4220\n",
            "\r Predicted  220   F#3221\n",
            "\r Predicted  221   E4222\n",
            "\r Predicted  222   E4223\n",
            "\r Predicted  223   C#4224\n",
            "\r Predicted  224   D4225\n",
            "\r Predicted  225   C#3226\n",
            "\r Predicted  226   C4227\n",
            "\r Predicted  227   F#3228\n",
            "\r Predicted  228   B3229\n",
            "\r Predicted  229   B3230\n",
            "\r Predicted  230   B3231\n",
            "\r Predicted  231   F#3232\n",
            "\r Predicted  232   E4233\n",
            "\r Predicted  233   F#3234\n",
            "\r Predicted  234   6.9235\n",
            "\r Predicted  235   E4236\n",
            "\r Predicted  236   C#4237\n",
            "\r Predicted  237   6.9238\n",
            "\r Predicted  238   F#3239\n",
            "\r Predicted  239   D4240\n",
            "\r Predicted  240   F#3241\n",
            "\r Predicted  241   E4242\n",
            "\r Predicted  242   A4243\n",
            "\r Predicted  243   F#3244\n",
            "\r Predicted  244   A3245\n",
            "\r Predicted  245   F#3246\n",
            "\r Predicted  246   C4247\n",
            "\r Predicted  247   E4248\n",
            "\r Predicted  248   B3249\n",
            "\r Predicted  249   C#4250\n",
            "\r Predicted  250   A4251\n",
            "\r Predicted  251   2.6.9252\n",
            "\r Predicted  252   B3253\n",
            "\r Predicted  253   9.0254\n",
            "\r Predicted  254   G3255\n",
            "\r Predicted  255   G#2256\n",
            "\r Predicted  256   B3257\n",
            "\r Predicted  257   2.7258\n",
            "\r Predicted  258   B3259\n",
            "\r Predicted  259   B3260\n",
            "\r Predicted  260   B3261\n",
            "\r Predicted  261   G2262\n",
            "\r Predicted  262   G2263\n",
            "\r Predicted  263   6.9264\n",
            "\r Predicted  264   G4265\n",
            "\r Predicted  265   C#4266\n",
            "\r Predicted  266   C#4267\n",
            "\r Predicted  267   C#4268\n",
            "\r Predicted  268   E4269\n",
            "\r Predicted  269   G4270\n",
            "\r Predicted  270   D3271\n",
            "\r Predicted  271   C#4272\n",
            "\r Predicted  272   B3273\n",
            "\r Predicted  273   G4274\n",
            "\r Predicted  274   D4275\n",
            "\r Predicted  275   E4276\n",
            "\r Predicted  276   D4277\n",
            "\r Predicted  277   A3278\n",
            "\r Predicted  278   B3279\n",
            "\r Predicted  279   2.5280\n",
            "\r Predicted  280   E3281\n",
            "\r Predicted  281   D4282\n",
            "\r Predicted  282   E4283\n",
            "\r Predicted  283   C#4284\n",
            "\r Predicted  284   E-4285\n",
            "\r Predicted  285   C#4286\n",
            "\r Predicted  286   C#4287\n",
            "\r Predicted  287   A4288\n",
            "\r Predicted  288   A4289\n",
            "\r Predicted  289   G#4290\n",
            "\r Predicted  290   E3291\n",
            "\r Predicted  291   C#4292\n",
            "\r Predicted  292   C#4293\n",
            "\r Predicted  293   B3294\n",
            "\r Predicted  294   G#3295\n",
            "\r Predicted  295   C#4296\n",
            "\r Predicted  296   C#4297\n",
            "\r Predicted  297   A4298\n",
            "\r Predicted  298   F#4299\n",
            "\r Predicted  299   D4300\n",
            "\r Predicted  300   C#4301\n",
            "\r Predicted  301   A3302\n",
            "\r Predicted  302   E-3303\n",
            "\r Predicted  303   E4304\n",
            "\r Predicted  304   E4305\n",
            " Predicted  305   G#3306\n",
            " Predicted  306   C#4307\n",
            " Predicted  307   A4308\n",
            " Predicted  308   C#4309\n",
            " Predicted  309   A4310\n",
            " Predicted  310   A3311\n",
            " Predicted  311   G#3312\n",
            " Predicted  312   B-3313\n",
            " Predicted  313   A3314\n",
            " Predicted  314   E3315\n",
            " Predicted  315   A3316\n",
            " Predicted  316   C#4317\n",
            " Predicted  317   E-4318\n",
            " Predicted  318   C#4319\n",
            " Predicted  319   E-4320\n",
            " Predicted  320   E-4321\n",
            " Predicted  321   10.1322\n",
            " Predicted  322   10.2323\n",
            " Predicted  323   G#2324\n",
            " Predicted  324   C#3325\n",
            " Predicted  325   5326\n",
            " Predicted  326   10327\n",
            " Predicted  327   C3328\n",
            " Predicted  328   D3329\n",
            " Predicted  329   D3330\n",
            " Predicted  330   D3331\n",
            " Predicted  331   D3332\n",
            " Predicted  332   A2333\n",
            " Predicted  333   D4334\n",
            " Predicted  334   F3335\n",
            " Predicted  335   10.2.5336\n",
            " Predicted  336   10.2337\n",
            " Predicted  337   F4338\n",
            " Predicted  338   D3339\n",
            " Predicted  339   10340\n",
            " Predicted  340   10341\n",
            " Predicted  341   3.7.10342\n",
            " Predicted  342   E-4343\n",
            " Predicted  343   G4344\n",
            " Predicted  344   D4345\n",
            " Predicted  345   C3346\n",
            " Predicted  346   B-3347\n",
            " Predicted  347   D2348\n",
            " Predicted  348   7.10349\n",
            " Predicted  349   F4350\n",
            " Predicted  350   B-3351\n",
            " Predicted  351   D4352\n",
            " Predicted  352   F3353\n",
            " Predicted  353   7.10354\n",
            " Predicted  354   5.10355\n",
            " Predicted  355   5.10356\n",
            " Predicted  356   10.2.5357\n",
            " Predicted  357   D4358\n",
            " Predicted  358   G4359\n",
            " Predicted  359   E-5360\n",
            " Predicted  360   5.10361\n",
            " Predicted  361   F3362\n",
            " Predicted  362   E-3363\n",
            " Predicted  363   10.3364\n",
            " Predicted  364   C4365\n",
            " Predicted  365   G3366\n",
            " Predicted  366   E-4367\n",
            " Predicted  367   G4368\n",
            " Predicted  368   2.5369\n",
            " Predicted  369   E-4370\n",
            " Predicted  370   B-3371\n",
            " Predicted  371   5.10372\n",
            " Predicted  372   D4373\n",
            " Predicted  373   D3374\n",
            " Predicted  374   2.5375\n",
            " Predicted  375   10.3376\n",
            " Predicted  376   0.3377\n",
            " Predicted  377   C4378\n",
            " Predicted  378   F#2379\n",
            " Predicted  379   F3380\n",
            " Predicted  380   F3381\n",
            " Predicted  381   G3382\n",
            " Predicted  382   E-3383\n",
            " Predicted  383   2.5384\n",
            " Predicted  384   B-3385\n",
            " Predicted  385   B-3386\n",
            " Predicted  386   B-3387\n",
            " Predicted  387   B-3388\n",
            " Predicted  388   B-3389\n",
            " Predicted  389   C4390\n",
            " Predicted  390   B-3391\n",
            " Predicted  391   B-3392\n",
            " Predicted  392   5.10393\n",
            " Predicted  393   5.10394\n",
            " Predicted  394   G#3395\n",
            " Predicted  395   B-3396\n",
            " Predicted  396   B-3397\n",
            " Predicted  397   B-3398\n",
            " Predicted  398   B-3399\n",
            " Predicted  399   3.7400\n",
            " Predicted  400   6.11401\n",
            " Predicted  401   6.11402\n",
            " Predicted  402   F3403\n",
            " Predicted  403   F4404\n",
            " Predicted  404   B-3405\n",
            " Predicted  405   B-3406\n",
            " Predicted  406   E-4407\n",
            " Predicted  407   5.10408\n",
            " Predicted  408   5.10409\n",
            " Predicted  409   5.10410\n",
            " Predicted  410   B-2411\n",
            " Predicted  411   D4412\n",
            " Predicted  412   F#2413\n",
            " Predicted  413   E-3414\n",
            " Predicted  414   B-2415\n",
            " Predicted  415   5.10416\n",
            " Predicted  416   9.2417\n",
            " Predicted  417   2.7418\n",
            " Predicted  418   A3419\n",
            " Predicted  419   B-3420\n",
            " Predicted  420   D4421\n",
            " Predicted  421   F#3422\n",
            " Predicted  422   F#3423\n",
            " Predicted  423   6.11424\n",
            " Predicted  424   6.11425\n",
            " Predicted  425   F#3426\n",
            " Predicted  426   F#3427\n",
            " Predicted  427   B-3428\n",
            " Predicted  428   3.7429\n",
            " Predicted  429   D4430\n",
            " Predicted  430   B-3431\n",
            " Predicted  431   C4432\n",
            " Predicted  432   F3433\n",
            " Predicted  433   B-3434\n",
            " Predicted  434   B-3435\n",
            " Predicted  435   B-3436\n",
            " Predicted  436   B-3437\n",
            " Predicted  437   B-3438\n",
            " Predicted  438   E-4439\n",
            " Predicted  439   B-1440\n",
            " Predicted  440   D4441\n",
            " Predicted  441   D4442\n",
            " Predicted  442   G4443\n",
            " Predicted  443   6.11444\n",
            " Predicted  444   5.10445\n",
            " Predicted  445   5.10446\n",
            " Predicted  446   6.11447\n",
            " Predicted  447   6.11448\n",
            " Predicted  448   A3449\n",
            " Predicted  449   A3450\n",
            " Predicted  450   G2451\n",
            " Predicted  451   F2452\n",
            " Predicted  452   F2453\n",
            " Predicted  453   C3454\n",
            " Predicted  454   D3455\n",
            " Predicted  455   B-1456\n",
            " Predicted  456   B-2457\n",
            " Predicted  457   B-2458\n",
            " Predicted  458   G2459\n",
            " Predicted  459   G2460\n",
            " Predicted  460   G2461\n",
            " Predicted  461   B-2462\n",
            " Predicted  462   B-2463\n",
            " Predicted  463   F3464\n",
            " Predicted  464   F3465\n",
            " Predicted  465   F3466\n",
            " Predicted  466   F3467\n",
            " Predicted  467   F3468\n",
            " Predicted  468   F3469\n",
            " Predicted  469   F3470\n",
            " Predicted  470   B-2471\n",
            " Predicted  471   F4472\n",
            " Predicted  472   B-2473\n",
            " Predicted  473   F3474\n",
            " Predicted  474   F3475\n",
            " Predicted  475   F3476\n",
            " Predicted  476   B-2477\n",
            " Predicted  477   B-2478\n",
            " Predicted  478   F3479\n",
            " Predicted  479   F3480\n",
            " Predicted  480   F3481\n",
            " Predicted  481   F4482\n",
            " Predicted  482   B-2483\n",
            " Predicted  483   F3484\n",
            " Predicted  484   10.2.5485\n",
            " Predicted  485   0.5486\n",
            " Predicted  486   F3487\n",
            " Predicted  487   F3488\n",
            " Predicted  488   F3489\n",
            " Predicted  489   F3490\n",
            " Predicted  490   F3491\n",
            " Predicted  491   5.10492\n",
            " Predicted  492   5.10493\n",
            " Predicted  493   5.10494\n",
            " Predicted  494   C#3495\n",
            " Predicted  495   B-3496\n",
            " Predicted  496   5.10497\n",
            " Predicted  497   5.10498\n",
            " Predicted  498   D4499\n",
            " Predicted  499   B-3"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lp5WcPlghe5"
      },
      "source": [
        "The last step is creating a MIDI file from the predictions.\n",
        "\n",
        "**music21** will help us again for this task. We should create a **Stream** and add to it the predicted notes and chords.\n",
        "\n",
        "We are adding an offset of 0.5 between elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7xYCPULXwV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25da8b99-55bc-45d7-94c7-2c9b696a97f8"
      },
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in prediction_output:\n",
        "    # pattern is a chord\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_output.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}