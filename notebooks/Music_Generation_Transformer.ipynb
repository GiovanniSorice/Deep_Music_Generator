{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generation_Transformer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNkiIkOuXdsrsWc9pCkV60i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Deep_Music_Generator/blob/main/notebooks/Music_Generation_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ3GwlYmvNT"
      },
      "source": [
        "# Transformer Music Generator "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNwQUwLIm7oW"
      },
      "source": [
        "\n",
        "\n",
        "In this notebook, we use an Transformer to generate some music.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFVGA5D4azA4"
      },
      "source": [
        "**This notebook was inspired (and part of the code comes from it) by [Music_Generation_LSTM](https://colab.research.google.com/drive/19TQqekOlnOSW36VCL8CPVEQKBBukmaEQ#scrollTo=DDOBVWULXfpz)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtmj0efInB_L"
      },
      "source": [
        "\n",
        "\n",
        "**Load dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCsb9kaJmWHN",
        "outputId": "1d9cf464-0b1d-4824-b480-63207cadbc9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install compressive_transformer_pytorch"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting compressive_transformer_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/30/39/b8caf2671abcb8615977c08766aa9f450addd6949f57c7dda87224e844b5/compressive_transformer_pytorch-0.3.20-py3-none-any.whl\n",
            "Collecting mogrifier\n",
            "  Downloading https://files.pythonhosted.org/packages/77/01/62a55d0f8048e788fce435f2ade6478f443e4e53ed9b89b55ba0fc42c198/mogrifier-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from compressive_transformer_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->compressive_transformer_pytorch) (0.16.0)\n",
            "Installing collected packages: mogrifier, compressive-transformer-pytorch\n",
            "Successfully installed compressive-transformer-pytorch-0.3.20 mogrifier-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mi6KoBmX44A"
      },
      "source": [
        "import torch\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from compressive_transformer_pytorch import CompressiveTransformer\n",
        "from compressive_transformer_pytorch import AutoregressiveWrapper\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tensorflow.keras import utils\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import pickle\n",
        "from music21 import converter, instrument, stream, note, chord"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwF2wx4oRZXW"
      },
      "source": [
        "# Set to false if you are not running\n",
        "# this notebook in Google Colaboratory\n",
        "run_on_colab = True"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2w9a2MknGmP"
      },
      "source": [
        "**Set hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnnLeO8Emsx3"
      },
      "source": [
        "# output directory name:\n",
        "output_dir = 'model_output/Transformer'\n",
        "\n",
        "# training:\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "max_batch_size=4\n",
        "learning_rate=1e-1\n",
        "# vector-space embedding: \n",
        "n_dim = 64 \n",
        "sequence_length = 16\n",
        "\n",
        "\n",
        "VALIDATE_EVERY  = 100\n",
        "\n",
        "GENERATE_EVERY  = 500\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvBjPl0cbI0_"
      },
      "source": [
        "**Google drive configuration (only Colab)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKil2p6sM2gZ",
        "outputId": "aee8534f-c4fa-466d-cb12-a6dab09205fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if(run_on_colab):\n",
        "  from google.colab import drive\n",
        "  # This will prompt for authorization.\n",
        "  drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU3gQinYmutQ"
      },
      "source": [
        "**Load data** \\\\\n",
        "Original MIDI files\n",
        " I have obtained  **MIDI files** from [The Lakh MIDI Dataset v0.1](https://colinraffel.com/projects/lmd/). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wavgJZNpcR_f"
      },
      "source": [
        "## Processing data\n",
        "\n",
        "Let's process the files, and load them into **music21**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vILKBwYIcOvX",
        "outputId": "e082383a-081b-45ad-b745-492e7f90953b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "file = \"/content/drive/My Drive/ISPR_project/midi_songs/Andra tutto bene ('58).1.mid\"\n",
        "midi = converter.parse(file)\n",
        "notes_to_parse = midi.flat.notes\n",
        "for element in notes_to_parse[:10]:\n",
        "  print(element, element.offset)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<music21.chord.Chord F3 F2> 4.0\n",
            "<music21.note.Note A> 4.0\n",
            "<music21.chord.Chord B1 F#3 F#2> 4.0\n",
            "<music21.note.Note F> 4.0\n",
            "<music21.chord.Chord C4 F4> 4.0\n",
            "<music21.chord.Chord F#3 C#6 F#2> 4.5\n",
            "<music21.note.Note C#> 4.75\n",
            "<music21.chord.Chord F#2 E2 F#3> 5.0\n",
            "<music21.chord.Chord A4 A3 F4 C4 A3> 5.0\n",
            "<music21.note.Note F> 5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjyrXfKic2kI"
      },
      "source": [
        "I will process all MIDI files obtaining data from each note of chord.\n",
        "\n",
        "- If I process a **note**, I will store in the list a string representing the pitch (the note name) and the octave.\n",
        "\n",
        "- If I process a **chord** (Remember that chords are set of notes that are played at the same time) I will store a different type of string with numbers separated by dots. Each number represents the pitch of a chord note. \n",
        "\n",
        "As you can see, **I are not considering yet time offsets of each element**. In this first version, we won't consider them, so all the notes and chords will have the same duration. Maybe, in the future, I will consider them.\n",
        "\n",
        "I are creating a big list with all the elements of all the compositions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iawbQHYVTOFM",
        "outputId": "de8226e3-bc41-4a23-9511-50973e396a28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "notes = []\n",
        "for i,file in enumerate(glob.glob(\"/content/drive/My Drive/ISPR_project/midi_songs/*.mid\")):\n",
        "  midi = converter.parse(file)\n",
        "  print('\\r', 'Parsing file ', i, \" \",file, end='')\n",
        "  notes_to_parse = None\n",
        "  try: # file has instrument parts\n",
        "    s2 = instrument.partitionByInstrument(midi)\n",
        "    notes_to_parse = s2.parts[0].recurse() \n",
        "  except: # file has notes in a flat structure\n",
        "    notes_to_parse = midi.flat.notes\n",
        "  for element in notes_to_parse:\n",
        "    if isinstance(element, note.Note):\n",
        "      notes.append(str(element.pitch))\n",
        "    elif isinstance(element, chord.Chord):\n",
        "      notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "with open('notes', 'wb') as filepath:\n",
        "  pickle.dump(notes, filepath)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Parsing file  3   /content/drive/My Drive/ISPR_project/midi_songs/Andra tutto bene ('58).1.mid"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuHePM_3dMXM"
      },
      "source": [
        "I obtain the number of different notes in our dataset, because this will be the **number of possible output classes**  of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEiySfEnTzyz",
        "outputId": "5001d712-1601-48ef-bf5d-7c0cdd2fdd58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Count different possible outputs\n",
        "n_vocab = (len(set(notes)))\n",
        "n_vocab"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-mABhgUnTcV"
      },
      "source": [
        "**Preprocess data** \\\\\n",
        "Now, there is some **data processing** that I have to do:\n",
        "\n",
        "- I will map each pitch or chord to an integer\n",
        "- I will create pairs of input sequences and its corresponding output note\n",
        "\n",
        "I can try different **sequence_length** to obtain different results. In this first version, I will use a sequence_length of 100.\n",
        "\n",
        "The network will made its prediction of the next note (or chord), based on the previous *sequence_length* notes (or chords). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4PpfIFRnWIA"
      },
      "source": [
        "# get all pitch names\n",
        "pitchnames = sorted(set(item for item in notes))\n",
        "# create a dictionary to map pitches to integers\n",
        "note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "network_input = []\n",
        "network_output = []\n",
        "# create input sequences and the corresponding outputs\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "  # Map pitches of sequence_in to integers\n",
        "  network_input.append([note_to_int[char] for char in notes[i:i + sequence_length]])\n",
        "n_patterns = len(network_input)\n",
        "# reshape the input into a format compatible with LSTM layers\n",
        "network_input = np.reshape(network_input, (n_patterns, sequence_length))\n",
        "# normalize input\n",
        "#network_input = network_input / float(n_vocab)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRPauXUdq5Y"
      },
      "source": [
        "Let's see the new metwork_input size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8eQQMbxhUkN",
        "outputId": "2ec524a4-970a-4d94-f97f-9ec546e99c8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network_input.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4987, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6--Wc8UXnVgY"
      },
      "source": [
        "**Design neural network architecture** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ztPAQsnb7T"
      },
      "source": [
        "def create_network(sequence_length, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = CompressiveTransformer(\n",
        "    num_tokens = n_vocab,\n",
        "    dim = sequence_length,\n",
        "    depth = 6,\n",
        "    seq_len = sequence_length,\n",
        "    mem_len = sequence_length,\n",
        "    cmem_len = 256,\n",
        "    cmem_ratio = 4,\n",
        "    memory_layers = [5,6]\n",
        "    )\n",
        "\n",
        "    model = AutoregressiveWrapper(model)\n",
        "    model.cuda()\n",
        "    return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nsNVMocnhNC",
        "outputId": "ab0e813a-02e4-4802-f4eb-8e1af1a043c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = create_network(sequence_length,n_vocab)\n",
        "\n",
        "print(model)\n",
        "#for loss, aux_loss, _ in model(inputs, return_loss = True):\n",
        "#    (loss + aux_loss).backward()\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AutoregressiveWrapper(\n",
            "  (net): CompressiveTransformer(\n",
            "    (token_emb): Embedding(71, 16)\n",
            "    (to_model_dim): Identity()\n",
            "    (to_logits): Sequential(\n",
            "      (0): Identity()\n",
            "      (1): Linear(in_features=16, out_features=71, bias=True)\n",
            "    )\n",
            "    (attn_layers): ModuleList(\n",
            "      (0): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (1): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (2): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (3): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (4): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (5): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): SelfAttention(\n",
            "            (compress_mem_fn): ConvCompress(\n",
            "              (conv): Conv1d(16, 16, kernel_size=(4,), stride=(4,))\n",
            "            )\n",
            "            (to_q): Linear(in_features=16, out_features=16, bias=False)\n",
            "            (to_kv): Linear(in_features=16, out_features=32, bias=False)\n",
            "            (to_out): Linear(in_features=16, out_features=16, bias=True)\n",
            "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (reconstruction_attn_dropout): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "    )\n",
            "    (ff_layers): ModuleList(\n",
            "      (0): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (1): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (2): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (3): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (4): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "      (5): GRUGating(\n",
            "        (fn): PreNorm(\n",
            "          (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
            "          (fn): FeedForward(\n",
            "            (w1): Linear(in_features=16, out_features=64, bias=True)\n",
            "            (act): GELU()\n",
            "            (dropout): Dropout(p=0.0, inplace=False)\n",
            "            (w2): Linear(in_features=64, out_features=16, bias=True)\n",
            "          )\n",
            "        )\n",
            "        (gru): GRUCell(16, 16)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRKI1q5WjwcL"
      },
      "source": [
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "          yield data\n",
        "\n",
        "\n",
        "data_train = torch.from_numpy(network_input).cuda()\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=32) \n",
        "cycle_train_loader  = cycle(DataLoader(data_train, batch_size = 32))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60il158kxfq"
      },
      "source": [
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqX3PsrJkyNN",
        "outputId": "b8eee7f6-d8c0-4071-8896-416d6b2780d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(epochs), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "    avg_loss = 0.0\n",
        "    grad_accum_every = batch_size / max_batch_size\n",
        "\n",
        "    for mlm_loss, aux_loss, is_last in model(next(cycle_train_loader), max_batch_size = max_batch_size, return_loss = True):\n",
        "        loss = mlm_loss + aux_loss\n",
        "        (loss / grad_accum_every).backward()\n",
        "\n",
        "        avg_loss+=loss/batch_size;\n",
        "\n",
        "        \n",
        "        if is_last:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "    print(f'training loss: {avg_loss.item():.4f}')\n",
        "\n",
        "print('Training complete.')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training:   0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 0.8862\n",
            "training loss: 0.8651\n",
            "training loss: 0.9273\n",
            "training loss: 0.9819\n",
            "training loss: 0.8828\n",
            "training loss: 0.8966\n",
            "training loss: 0.8635\n",
            "training loss: 0.9492\n",
            "training loss: 0.8561\n",
            "training loss: 0.7338\n",
            "training loss: 0.8892\n",
            "training loss: 0.8995\n",
            "training loss: 0.7427\n",
            "training loss: 1.0554\n",
            "training loss: 1.0671\n",
            "training loss: 0.8517\n",
            "training loss: 0.6186\n",
            "training loss: 0.5559\n",
            "training loss: 0.4928\n",
            "training loss: 0.4356\n",
            "training loss: 0.4190\n",
            "training loss: 0.4360\n",
            "training loss: 1.6494\n",
            "training loss: 1.7879\n",
            "training loss: 1.7013\n",
            "training loss: 1.5919\n",
            "training loss: 1.6565\n",
            "training loss: 0.9834\n",
            "training loss: 1.1374\n",
            "training loss: 0.9051\n",
            "training loss: 0.8638\n",
            "training loss: 1.1797\n",
            "training loss: 1.0949\n",
            "training loss: 0.8970\n",
            "training loss: 2.0774\n",
            "training loss: 2.1825\n",
            "training loss: 1.8995\n",
            "training loss: 2.0409\n",
            "training loss: 1.3838\n",
            "training loss: 1.1878\n",
            "training loss: 1.0832\n",
            "training loss: 1.5420\n",
            "training loss: 1.7655\n",
            "training loss: 1.6899\n",
            "training loss: 2.3685\n",
            "training loss: 2.4867\n",
            "training loss: 2.1438\n",
            "training loss: 1.8242\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "training:  50%|█████     | 50/100 [00:10<00:10,  4.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 1.5679\n",
            "training loss: 1.2198\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training:  51%|█████     | 51/100 [00:30<00:09,  5.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 1.3785\n",
            "training loss: 1.1233\n",
            "training loss: 0.9529\n",
            "training loss: 1.2272\n",
            "training loss: 1.1438\n",
            "training loss: 1.4745\n",
            "training loss: 1.3102\n",
            "training loss: 0.8996\n",
            "training loss: 1.0432\n",
            "training loss: 1.1418\n",
            "training loss: 1.0032\n",
            "training loss: 1.1581\n",
            "training loss: 0.9525\n",
            "training loss: 0.7799\n",
            "training loss: 0.8819\n",
            "training loss: 0.8967\n",
            "training loss: 0.7695\n",
            "training loss: 1.0040\n",
            "training loss: 0.8082\n",
            "training loss: 0.7679\n",
            "training loss: 1.0046\n",
            "training loss: 0.8354\n",
            "training loss: 0.8012\n",
            "training loss: 0.8823\n",
            "training loss: 0.6618\n",
            "training loss: 0.7689\n",
            "training loss: 0.8271\n",
            "training loss: 0.8306\n",
            "training loss: 1.0038\n",
            "training loss: 0.6479\n",
            "training loss: 0.6644\n",
            "training loss: 0.8270\n",
            "training loss: 0.8321\n",
            "training loss: 0.9220\n",
            "training loss: 0.7226\n",
            "training loss: 0.6649\n",
            "training loss: 0.8286\n",
            "training loss: 0.8174\n",
            "training loss: 0.6721\n",
            "training loss: 2.6208\n",
            "training loss: 2.6112\n",
            "training loss: 3.7898\n",
            "training loss: 2.1128\n",
            "training loss: 1.7219\n",
            "training loss: 1.2591\n",
            "training loss: 1.8730\n",
            "training loss: 1.1296\n",
            "training loss: 1.2747\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rtraining: 100%|██████████| 100/100 [00:19<00:00,  5.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 1.4283\n",
            "training loss: 1.6007\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2a4iB729Nzj",
        "outputId": "d12e9508-0fdb-4862-9da4-e29cc2d62994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "size_input = np.array((1,16))\n",
        "size_input.shape\n",
        "#summary(model, size_input)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbO-XA3Dfrd2"
      },
      "source": [
        "In case we want to use previously trained weights, to continue the training in the point we left it, we should load them into the model.\n",
        "\n",
        "This is very useful in Google Colaboratory, that usually kills the virtual machine that is executing the Jupyter notework after a certime amount of time. If this happens to you, you should have to look for the last weights file in your configured Drive account and use it to train the network.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFbSthkLUwmx"
      },
      "source": [
        "# In case we want to use previously trained weights\n",
        "weights = \"\"\n",
        "if(len(weights)>0): model.load_weights(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqyWj37PnfaS"
      },
      "source": [
        "**Configure model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiAxaVxlnpS5"
      },
      "source": [
        "filepath = \"/content/drive/My Drive/ISPR_project/LSTM{epoch:02d}-{loss:.4f}.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',verbose=0,\n",
        "                             save_best_only=True,mode='min')\n",
        "\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAgrzFyRn3uq"
      },
      "source": [
        "**Music generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1CA_EQdoN5P",
        "outputId": "c545d547-9186-4805-e30f-67425a246ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "source": [
        "# In case we want to use other previously trained weights\n",
        "weights = \"path/to/weights\"\n",
        "if(len(weights)>0): model.load_weights(weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-44fe414b8109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# In case we want to use other previously trained weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"path/to/weights\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2175\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2176\u001b[0;31m         \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2177\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2178\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     93\u001b[0m   \"\"\"\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on path/to/weights: Not found: path/to; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WtYEXpyoPPK"
      },
      "source": [
        "# Generate network input again\n",
        "network_input = []\n",
        "output = []\n",
        "for i in range(0, len(notes) - sequence_length, 1):\n",
        "  sequence_in = notes[i:i + sequence_length]\n",
        "  sequence_out = notes[i + sequence_length]\n",
        "  network_input.append([note_to_int[char] for char in sequence_in])\n",
        "  output.append(note_to_int[sequence_out])\n",
        "n_patterns = len(network_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuUGi5rVgbJQ"
      },
      "source": [
        "The workflow now is:\n",
        "\n",
        "\n",
        "1.   Pick a **seed sequence** randomly from your list of inputs (*pattern* variable)\n",
        "2.   Pass it as input for your model to generate a new element (note or chord)\n",
        "3.   Add the new element to your final song and to your *pattern* list\n",
        "4.   Remove the first item from *pattern*\n",
        "5.   Go to step 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUTEiS0NXtkl"
      },
      "source": [
        "\"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "# pick a random sequence from the input as a starting point for the prediction\n",
        "start = np.random.randint(0, len(network_input)-1)\n",
        "int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "pattern = torch.from_numpy(network_input[start]).cuda()\n",
        "\n",
        "prediction_output = model.generate(pattern, 500)\n"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myG-DGWh__-g",
        "outputId": "c254682e-d693-4140-d4a8-056f983927bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<enumerate object at 0x7efbbf11ce10>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUlgtok68w-w",
        "outputId": "50e0585a-dbe4-48bc-83c4-e29407dab42b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "result_sample=[]\n",
        "\n",
        "for i in range(500):\n",
        "  print(i)\n",
        "  result = int_to_note[prediction_output[i].item()]\n",
        "  print('\\r', 'Predicted ', i, \" \",result, end='')\n",
        "  result_sample.append(result)\n",
        "\n",
        "prediction_output=result_sample"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "\r Predicted  0   61\n",
            "\r Predicted  1   G52\n",
            "\r Predicted  2   4.6.113\n",
            "\r Predicted  3   G44\n",
            "\r Predicted  4   G55\n",
            "\r Predicted  5   F#36\n",
            "\r Predicted  6   G57\n",
            "\r Predicted  7   C58\n",
            "\r Predicted  8   F#39\n",
            "\r Predicted  9   G410\n",
            "\r Predicted  10   C511\n",
            "\r Predicted  11   G112\n",
            "\r Predicted  12   G513\n",
            "\r Predicted  13   G114\n",
            "\r Predicted  14   C515\n",
            "\r Predicted  15   G516\n",
            "\r Predicted  16   F#317\n",
            "\r Predicted  17   F#318\n",
            "\r Predicted  18   G119\n",
            "\r Predicted  19   G520\n",
            "\r Predicted  20   C521\n",
            "\r Predicted  21   G122\n",
            "\r Predicted  22   C523\n",
            "\r Predicted  23   G524\n",
            "\r Predicted  24   625\n",
            "\r Predicted  25   G526\n",
            "\r Predicted  26   C527\n",
            "\r Predicted  27   G528\n",
            "\r Predicted  28   4.6.1129\n",
            "\r Predicted  29   4.6.1130\n",
            "\r Predicted  30   G131\n",
            "\r Predicted  31   F#332\n",
            "\r Predicted  32   633\n",
            "\r Predicted  33   F#334\n",
            "\r Predicted  34   G435\n",
            "\r Predicted  35   G436\n",
            "\r Predicted  36   G537\n",
            "\r Predicted  37   G438\n",
            "\r Predicted  38   G439\n",
            "\r Predicted  39   F#340\n",
            "\r Predicted  40   F#341\n",
            "\r Predicted  41   F#342\n",
            "\r Predicted  42   C543\n",
            "\r Predicted  43   F#344\n",
            "\r Predicted  44   645\n",
            "\r Predicted  45   646\n",
            "\r Predicted  46   G447\n",
            "\r Predicted  47   G548\n",
            "\r Predicted  48   G549\n",
            "\r Predicted  49   G150\n",
            "\r Predicted  50   F#351\n",
            "\r Predicted  51   G452\n",
            "\r Predicted  52   G453\n",
            "\r Predicted  53   G454\n",
            "\r Predicted  54   F#355\n",
            "\r Predicted  55   G556\n",
            "\r Predicted  56   G457\n",
            "\r Predicted  57   F#358\n",
            "\r Predicted  58   659\n",
            "\r Predicted  59   F#360\n",
            "\r Predicted  60   4.6.1161\n",
            "\r Predicted  61   F#362\n",
            "\r Predicted  62   G563\n",
            "\r Predicted  63   G564\n",
            "\r Predicted  64   665\n",
            "\r Predicted  65   4.6.1166\n",
            "\r Predicted  66   667\n",
            "\r Predicted  67   668\n",
            "\r Predicted  68   G469\n",
            "\r Predicted  69   G470\n",
            "\r Predicted  70   G471\n",
            "\r Predicted  71   G572\n",
            "\r Predicted  72   673\n",
            "\r Predicted  73   G474\n",
            "\r Predicted  74   G575\n",
            "\r Predicted  75   676\n",
            "\r Predicted  76   677\n",
            "\r Predicted  77   4.6.1178\n",
            "\r Predicted  78   G579\n",
            "\r Predicted  79   F#380\n",
            "\r Predicted  80   681\n",
            "\r Predicted  81   682\n",
            "\r Predicted  82   G483\n",
            "\r Predicted  83   G484\n",
            "\r Predicted  84   C585\n",
            "\r Predicted  85   F#386\n",
            "\r Predicted  86   F#387\n",
            "\r Predicted  87   F#388\n",
            "\r Predicted  88   G489\n",
            "\r Predicted  89   G590\n",
            "\r Predicted  90   G491\n",
            "\r Predicted  91   F#392\n",
            "\r Predicted  92   G193\n",
            "\r Predicted  93   694\n",
            "\r Predicted  94   C595\n",
            "\r Predicted  95   G596\n",
            "\r Predicted  96   G497\n",
            "\r Predicted  97   G198\n",
            "\r Predicted  98   G599\n",
            "\r Predicted  99   G4100\n",
            "\r Predicted  100   G5101\n",
            "\r Predicted  101   4.6.11102\n",
            "\r Predicted  102   G4103\n",
            "\r Predicted  103   G1104\n",
            "\r Predicted  104   F#3105\n",
            "\r Predicted  105   G4106\n",
            "\r Predicted  106   6107\n",
            "\r Predicted  107   F#3108\n",
            "\r Predicted  108   4.6.11109\n",
            "\r Predicted  109   G4110\n",
            "\r Predicted  110   6111\n",
            "\r Predicted  111   F#3112\n",
            "\r Predicted  112   F#3113\n",
            "\r Predicted  113   F#3114\n",
            "\r Predicted  114   F#3115\n",
            "\r Predicted  115   F#3116\n",
            "\r Predicted  116   G5117\n",
            "\r Predicted  117   F#3118\n",
            "\r Predicted  118   F#3119\n",
            "\r Predicted  119   G5120\n",
            "\r Predicted  120   F#3121\n",
            "\r Predicted  121   G1122\n",
            "\r Predicted  122   G4123\n",
            "\r Predicted  123   F#3124\n",
            "\r Predicted  124   6125\n",
            "\r Predicted  125   F#3126\n",
            "\r Predicted  126   C5127\n",
            "\r Predicted  127   F#3128\n",
            "\r Predicted  128   G1129\n",
            "\r Predicted  129   G4130\n",
            "\r Predicted  130   F#3131\n",
            "\r Predicted  131   F#3132\n",
            "\r Predicted  132   4.6.11133\n",
            "\r Predicted  133   6134\n",
            "\r Predicted  134   F#3135\n",
            "\r Predicted  135   G1136\n",
            "\r Predicted  136   G5137\n",
            "\r Predicted  137   G4138\n",
            "\r Predicted  138   C5139\n",
            "\r Predicted  139   G5140\n",
            "\r Predicted  140   F#3141\n",
            "\r Predicted  141   G5142\n",
            "\r Predicted  142   F#3143\n",
            "\r Predicted  143   G5144\n",
            "\r Predicted  144   6145\n",
            "\r Predicted  145   G1146\n",
            "\r Predicted  146   G5147\n",
            "\r Predicted  147   6148\n",
            "\r Predicted  148   G5149\n",
            "\r Predicted  149   6150\n",
            "\r Predicted  150   G5151\n",
            "\r Predicted  151   G5152\n",
            "\r Predicted  152   G4153\n",
            "\r Predicted  153   F#3154\n",
            "\r Predicted  154   G5155\n",
            "\r Predicted  155   G4156\n",
            "\r Predicted  156   F#3157\n",
            "\r Predicted  157   C5158\n",
            "\r Predicted  158   G1159\n",
            "\r Predicted  159   F#3160\n",
            "\r Predicted  160   F#3161\n",
            "\r Predicted  161   G5162\n",
            "\r Predicted  162   C5163\n",
            "\r Predicted  163   C5164\n",
            "\r Predicted  164   G4165\n",
            "\r Predicted  165   G1166\n",
            "\r Predicted  166   G4167\n",
            "\r Predicted  167   F#3168\n",
            "\r Predicted  168   G4169\n",
            "\r Predicted  169   C5170\n",
            "\r Predicted  170   F#3171\n",
            "\r Predicted  171   4.6.11172\n",
            "\r Predicted  172   F#3173\n",
            "\r Predicted  173   F#3174\n",
            "\r Predicted  174   C5175\n",
            "\r Predicted  175   G1176\n",
            "\r Predicted  176   F#3177\n",
            "\r Predicted  177   G4178\n",
            "\r Predicted  178   F#3179\n",
            "\r Predicted  179   G5180\n",
            "\r Predicted  180   F#3181\n",
            "\r Predicted  181   F#3182\n",
            "\r Predicted  182   G4183\n",
            "\r Predicted  183   C5184\n",
            "\r Predicted  184   F#3185\n",
            "\r Predicted  185   G4186\n",
            "\r Predicted  186   6187\n",
            "\r Predicted  187   G5188\n",
            "\r Predicted  188   F#3189\n",
            "\r Predicted  189   F#3190\n",
            "\r Predicted  190   G5191\n",
            "\r Predicted  191   C5192\n",
            "\r Predicted  192   G5193\n",
            "\r Predicted  193   G4194\n",
            "\r Predicted  194   6195\n",
            "\r Predicted  195   C5196\n",
            "\r Predicted  196   F#3197\n",
            "\r Predicted  197   4.6.11198\n",
            "\r Predicted  198   F#3199\n",
            "\r Predicted  199   C5200\n",
            "\r Predicted  200   4.6.11201\n",
            "\r Predicted  201   G5202\n",
            "\r Predicted  202   F#3203\n",
            "\r Predicted  203   F#3204\n",
            "\r Predicted  204   G5205\n",
            "\r Predicted  205   G4206\n",
            "\r Predicted  206   G4207\n",
            "\r Predicted  207   C5208\n",
            "\r Predicted  208   6209\n",
            "\r Predicted  209   F#3210\n",
            "\r Predicted  210   G4211\n",
            "\r Predicted  211   G5212\n",
            "\r Predicted  212   6213\n",
            "\r Predicted  213   F#3214\n",
            "\r Predicted  214   G4215\n",
            "\r Predicted  215   G1216\n",
            "\r Predicted  216   F#3217\n",
            "\r Predicted  217   G5218\n",
            "\r Predicted  218   G5219\n",
            "\r Predicted  219   F#3220\n",
            "\r Predicted  220   F#3221\n",
            "\r Predicted  221   6222\n",
            "\r Predicted  222   G4223\n",
            "\r Predicted  223   G4224\n",
            "\r Predicted  224   F#3225\n",
            "\r Predicted  225   4.6.11226\n",
            "\r Predicted  226   6227\n",
            "\r Predicted  227   4.6.11228\n",
            "\r Predicted  228   G4229\n",
            "\r Predicted  229   F#3230\n",
            "\r Predicted  230   4.6.11231\n",
            "\r Predicted  231   F#3232\n",
            "\r Predicted  232   G4233\n",
            "\r Predicted  233   6234\n",
            "\r Predicted  234   6235\n",
            "\r Predicted  235   F#3236\n",
            "\r Predicted  236   C5237\n",
            "\r Predicted  237   F#3238\n",
            "\r Predicted  238   F#3239\n",
            "\r Predicted  239   6240\n",
            "\r Predicted  240   G5241\n",
            "\r Predicted  241   G5242\n",
            "\r Predicted  242   F#3243\n",
            "\r Predicted  243   6244\n",
            "\r Predicted  244   6245\n",
            "\r Predicted  245   4.6.11246\n",
            "\r Predicted  246   F#3247\n",
            "\r Predicted  247   F#3248\n",
            "\r Predicted  248   F#3249\n",
            "\r Predicted  249   G1250\n",
            "\r Predicted  250   6251\n",
            "\r Predicted  251   F#3252\n",
            "\r Predicted  252   G4253\n",
            "\r Predicted  253   G1254\n",
            "\r Predicted  254   6255\n",
            "\r Predicted  255   F#3256\n",
            "\r Predicted  256   F#3257\n",
            "\r Predicted  257   G5258\n",
            "\r Predicted  258   G4259\n",
            "\r Predicted  259   F#3260\n",
            "\r Predicted  260   6261\n",
            "\r Predicted  261   G1262\n",
            "\r Predicted  262   F#3263\n",
            "\r Predicted  263   F#3264\n",
            "\r Predicted  264   G5265\n",
            "\r Predicted  265   F#3266\n",
            "\r Predicted  266   F#3267\n",
            "\r Predicted  267   G1268\n",
            "\r Predicted  268   G5269\n",
            "\r Predicted  269   6270\n",
            "\r Predicted  270   F#3271\n",
            "\r Predicted  271   G1272\n",
            "\r Predicted  272   6273\n",
            "\r Predicted  273   6274\n",
            "\r Predicted  274   G5275\n",
            "\r Predicted  275   F#3276\n",
            "\r Predicted  276   4.6.11277\n",
            "\r Predicted  277   F#3278\n",
            "\r Predicted  278   G4279\n",
            "\r Predicted  279   G4280\n",
            "\r Predicted  280   6281\n",
            "\r Predicted  281   6282\n",
            "\r Predicted  282   F#3283\n",
            "\r Predicted  283   G1284\n",
            "\r Predicted  284   G4285\n",
            "\r Predicted  285   F#3286\n",
            "\r Predicted  286   G4287\n",
            "\r Predicted  287   F#3288\n",
            "\r Predicted  288   C5289\n",
            "\r Predicted  289   G4290\n",
            "\r Predicted  290   G1291\n",
            "\r Predicted  291   G4292\n",
            "\r Predicted  292   6293\n",
            "\r Predicted  293   F#3294\n",
            "\r Predicted  294   G4295\n",
            "\r Predicted  295   6296\n",
            "\r Predicted  296   6297\n",
            "\r Predicted  297   F#3298\n",
            "\r Predicted  298   G5299\n",
            "\r Predicted  299   6300\n",
            "\r Predicted  300   C5301\n",
            "\r Predicted  301   G4302\n",
            "\r Predicted  302   G4303\n",
            "\r Predicted  303   F#3304\n",
            "\r Predicted  304   G4305\n",
            "\r Predicted  305   F#3306\n",
            "\r Predicted  306   G5307\n",
            "\r Predicted  307   C5308\n",
            "\r Predicted  308   G4309\n",
            "\r Predicted  309   4.6.11310\n",
            "\r Predicted  310   G5311\n",
            "\r Predicted  311   G4312\n",
            "\r Predicted  312   G1313\n",
            "\r Predicted  313   C5314\n",
            "\r Predicted  314   G4315\n",
            "\r Predicted  315   F#3316\n",
            "\r Predicted  316   F#3317\n",
            "\r Predicted  317   C5318\n",
            "\r Predicted  318   F#3319\n",
            "\r Predicted  319   F#3320\n",
            "\r Predicted  320   G5321\n",
            "\r Predicted  321   G4322\n",
            "\r Predicted  322   F#3323\n",
            "\r Predicted  323   F#3324\n",
            "\r Predicted  324   G1325\n",
            "\r Predicted  325   G4326\n",
            "\r Predicted  326   G4327\n",
            "\r Predicted  327   F#3328\n",
            "\r Predicted  328   G5329\n",
            "\r Predicted  329   6330\n",
            "\r Predicted  330   F#3331\n",
            "\r Predicted  331   6332\n",
            "\r Predicted  332   6333\n",
            "\r Predicted  333   F#3334\n",
            "\r Predicted  334   G5335\n",
            "\r Predicted  335   G1336\n",
            "\r Predicted  336   G1337\n",
            "\r Predicted  337   F#3338\n",
            "\r Predicted  338   F#3339\n",
            "\r Predicted  339   G4340\n",
            "\r Predicted  340   F#3341\n",
            "\r Predicted  341   6342\n",
            "\r Predicted  342   F#3343\n",
            "\r Predicted  343   6344\n",
            "\r Predicted  344   F#3345\n",
            "\r Predicted  345   C5346\n",
            "\r Predicted  346   C5347\n",
            " Predicted  347   4.6.11348\n",
            " Predicted  348   6349\n",
            " Predicted  349   C5350\n",
            " Predicted  350   G5351\n",
            " Predicted  351   G5352\n",
            " Predicted  352   G5353\n",
            " Predicted  353   F#3354\n",
            " Predicted  354   F#3355\n",
            " Predicted  355   G1356\n",
            " Predicted  356   G5357\n",
            " Predicted  357   F#3358\n",
            " Predicted  358   G5359\n",
            " Predicted  359   G4360\n",
            " Predicted  360   F#3361\n",
            " Predicted  361   4.6.11362\n",
            " Predicted  362   G4363\n",
            " Predicted  363   G4364\n",
            " Predicted  364   F#3365\n",
            " Predicted  365   G5366\n",
            " Predicted  366   6367\n",
            " Predicted  367   4.6.11368\n",
            " Predicted  368   G4369\n",
            " Predicted  369   6370\n",
            " Predicted  370   F#3371\n",
            " Predicted  371   6372\n",
            " Predicted  372   6373\n",
            " Predicted  373   G5374\n",
            " Predicted  374   F#3375\n",
            " Predicted  375   G5376\n",
            " Predicted  376   G4377\n",
            " Predicted  377   6378\n",
            " Predicted  378   F#3379\n",
            " Predicted  379   C5380\n",
            " Predicted  380   G5381\n",
            " Predicted  381   G5382\n",
            " Predicted  382   F#3383\n",
            " Predicted  383   6384\n",
            " Predicted  384   G1385\n",
            " Predicted  385   C5386\n",
            " Predicted  386   G4387\n",
            " Predicted  387   G4388\n",
            " Predicted  388   F#3389\n",
            " Predicted  389   4.6.11390\n",
            " Predicted  390   G4391\n",
            " Predicted  391   F#3392\n",
            " Predicted  392   F#3393\n",
            " Predicted  393   G4394\n",
            " Predicted  394   F#3395\n",
            " Predicted  395   C5396\n",
            " Predicted  396   F#3397\n",
            " Predicted  397   6398\n",
            " Predicted  398   F#3399\n",
            " Predicted  399   G5400\n",
            " Predicted  400   6401\n",
            " Predicted  401   6402\n",
            " Predicted  402   C5403\n",
            " Predicted  403   G5404\n",
            " Predicted  404   F#3405\n",
            " Predicted  405   G5406\n",
            " Predicted  406   F#3407\n",
            " Predicted  407   G1408\n",
            " Predicted  408   6409\n",
            " Predicted  409   G5410\n",
            " Predicted  410   G4411\n",
            " Predicted  411   F#3412\n",
            " Predicted  412   F#3413\n",
            " Predicted  413   G1414\n",
            " Predicted  414   G5415\n",
            " Predicted  415   G5416\n",
            " Predicted  416   F#3417\n",
            " Predicted  417   F#3418\n",
            " Predicted  418   F#3419\n",
            " Predicted  419   6420\n",
            " Predicted  420   G4421\n",
            " Predicted  421   C5422\n",
            " Predicted  422   G1423\n",
            " Predicted  423   G1424\n",
            " Predicted  424   F#3425\n",
            " Predicted  425   G4426\n",
            " Predicted  426   G1427\n",
            " Predicted  427   G4428\n",
            " Predicted  428   F#3429\n",
            " Predicted  429   C5430\n",
            " Predicted  430   F#3431\n",
            " Predicted  431   G4432\n",
            " Predicted  432   C5433\n",
            " Predicted  433   F#3434\n",
            " Predicted  434   4.6.11435\n",
            " Predicted  435   F#3436\n",
            " Predicted  436   G5437\n",
            " Predicted  437   G5438\n",
            " Predicted  438   G1439\n",
            " Predicted  439   G5440\n",
            " Predicted  440   G4441\n",
            " Predicted  441   6442\n",
            " Predicted  442   G4443\n",
            " Predicted  443   G4444\n",
            " Predicted  444   F#3445\n",
            " Predicted  445   F#3446\n",
            " Predicted  446   G4447\n",
            " Predicted  447   G4448\n",
            " Predicted  448   F#3449\n",
            " Predicted  449   G5450\n",
            " Predicted  450   F#3451\n",
            " Predicted  451   F#3452\n",
            " Predicted  452   6453\n",
            " Predicted  453   F#3454\n",
            " Predicted  454   4.6.11455\n",
            " Predicted  455   4.6.11456\n",
            " Predicted  456   G1457\n",
            " Predicted  457   G4458\n",
            " Predicted  458   6459\n",
            " Predicted  459   F#3460\n",
            " Predicted  460   4.6.11461\n",
            " Predicted  461   F#3462\n",
            " Predicted  462   G4463\n",
            " Predicted  463   6464\n",
            " Predicted  464   G4465\n",
            " Predicted  465   F#3466\n",
            " Predicted  466   4.6.11467\n",
            " Predicted  467   6468\n",
            " Predicted  468   F#3469\n",
            " Predicted  469   F#3470\n",
            " Predicted  470   C5471\n",
            " Predicted  471   F#3472\n",
            " Predicted  472   4.6.11473\n",
            " Predicted  473   F#3474\n",
            " Predicted  474   F#3475\n",
            " Predicted  475   F#3476\n",
            " Predicted  476   G4477\n",
            " Predicted  477   F#3478\n",
            " Predicted  478   C5479\n",
            " Predicted  479   F#3480\n",
            " Predicted  480   F#3481\n",
            " Predicted  481   6482\n",
            " Predicted  482   F#3483\n",
            " Predicted  483   4.6.11484\n",
            " Predicted  484   G4485\n",
            " Predicted  485   F#3486\n",
            " Predicted  486   G4487\n",
            " Predicted  487   6488\n",
            " Predicted  488   G5489\n",
            " Predicted  489   G1490\n",
            " Predicted  490   G4491\n",
            " Predicted  491   F#3492\n",
            " Predicted  492   6493\n",
            " Predicted  493   G4494\n",
            " Predicted  494   F#3495\n",
            " Predicted  495   G4496\n",
            " Predicted  496   F#3497\n",
            " Predicted  497   6498\n",
            " Predicted  498   G4499\n",
            " Predicted  499   C5"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lp5WcPlghe5"
      },
      "source": [
        "The last step is creating a MIDI file from the predictions.\n",
        "\n",
        "**music21** will help us again for this task. We should create a **Stream** and add to it the predicted notes and chords.\n",
        "\n",
        "We are adding an offset of 0.5 between elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7xYCPULXwV-",
        "outputId": "9416ae86-eb70-406c-e3f6-09500eab3341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "offset = 0\n",
        "output_notes = []\n",
        "# create note and chord objects based on the values generated by the model\n",
        "for pattern in prediction_output:\n",
        "    # pattern is a chord\n",
        "    if ('.' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('.')\n",
        "        notes = []\n",
        "        for current_note in notes_in_chord:\n",
        "            new_note = note.Note(int(current_note))\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            notes.append(new_note)\n",
        "        new_chord = chord.Chord(notes)\n",
        "        new_chord.offset = offset\n",
        "        output_notes.append(new_chord)\n",
        "    # pattern is a note\n",
        "    else:\n",
        "        new_note = note.Note(pattern)\n",
        "        new_note.offset = offset\n",
        "        new_note.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "\n",
        "    # increase offset each iteration so that notes do not stack\n",
        "    offset += 0.5\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp='test_output.mid')"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'test_output.mid'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    }
  ]
}