\section{Introduction}
Starting from the early 1960s with Iannis Xenakis \cite{Iannis}, algorithmic compositions were first explored. The initial methods included stochastic composition through a set of probabilities designed by a composer and the use of grammar and rules to specify the style of a given corpus.
The task of music generation was not fully satisfied due to methodological and computational shortcomings. Nerveless, they saw that this kind of algorithms could become an excellent tool for assisting musicians.
The situation did not change until the neural networks came to the fore in 2012 with AlexNet \cite{AlexNet} in the competition ImageNet. From that point on, the use of neural networks has changed and they have also been used in the music generation field. Currently, different models were used like Feedforward neural network, Autoencoder, Restricted Boltzmann Machine, Recurrent Neural Network, Generative Adversarial Network but also Genetic algorithms and Agents based systems.

My goal is to use the compressed transformer model to generate music. I decided to develop this project because I think that the creation and generation of new music is one of the most creative tasks that the human can do. Also, I could explore and better understand a really important and stimulating machine learning model that is the Transformer.

The remaining report is structured as follows.
In \S2 you can find an explanation of the model used and comments on the result obtained and in \S3 there is a brief comment on other approaches, considerations on further improvements and a general comment on the experience.